{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction to shell (bash)\n\n\n\n\n\n\n\n\nAudience\n\n\nComputational Skills\n\n\nPrerequisites\n\n\nDuration\n\n\n\n\n\n\n\n\n\n\nBiologists\n\n\nBeginner/Intermediate\n\n\nNone\n\n\n1-day workshop (~6 hours of trainer-led time)\n\n\n\n\n\n\n\n\nDescription\n\n\nThis repository has teaching materials for a 1-day Introduction to shell workshop. This workshop focuses on teaching basic skills to use the command line interface, specifically \nbash\n, the lessons include \nfor\n loops, shell scripting, positional parameters. This workshop is a prerequisite to a workshop on \nRNA-seq analysis\n.\n\n\n\n\nThese materials were developed for a trainer-led workshop, but are also amenable to self-guided learning.\n\n\n\n\nLearning Objectives\n\n\n\n\nUnderstand the necessity for, and use of, the command line interface (bash/shell).\n\n\n\n\nContents\n\n\n\n\n\n\n\n\nLessons\n\n\nEstimated Duration\n\n\n\n\n\n\n\n\n\n\nIntroduction to the shell\n\n\n70 min\n\n\n\n\n\n\nSearching and redirection in shell\n\n\n45 min\n\n\n\n\n\n\nIntroduction to the Vim text editor\n\n\n30 min\n\n\n\n\n\n\nShell scripts and \nfor\n loops\n\n\n75 min\n\n\n\n\n\n\nPermissions and environment variables\n\n\n50 min\n\n\n\n\n\n\n\n\nDataset\n\n\n\n\nThese materials have been developed by members of the teaching team at the \nHarvard Chan Bioinformatics Core (HBC)\n. These are open access materials distributed under the terms of the \nCreative Commons Attribution license\n (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\n\n\n\nSome materials used in these lessons were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the \nCreative Commons Attribution license\n (CC BY 4.0).", 
            "title": "Home"
        }, 
        {
            "location": "/#introduction-to-shell-bash", 
            "text": "Audience  Computational Skills  Prerequisites  Duration      Biologists  Beginner/Intermediate  None  1-day workshop (~6 hours of trainer-led time)", 
            "title": "Introduction to shell (bash)"
        }, 
        {
            "location": "/#description", 
            "text": "This repository has teaching materials for a 1-day Introduction to shell workshop. This workshop focuses on teaching basic skills to use the command line interface, specifically  bash , the lessons include  for  loops, shell scripting, positional parameters. This workshop is a prerequisite to a workshop on  RNA-seq analysis .   These materials were developed for a trainer-led workshop, but are also amenable to self-guided learning.", 
            "title": "Description"
        }, 
        {
            "location": "/#learning-objectives", 
            "text": "Understand the necessity for, and use of, the command line interface (bash/shell).", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/#contents", 
            "text": "Lessons  Estimated Duration      Introduction to the shell  70 min    Searching and redirection in shell  45 min    Introduction to the Vim text editor  30 min    Shell scripts and  for  loops  75 min    Permissions and environment variables  50 min", 
            "title": "Contents"
        }, 
        {
            "location": "/#dataset", 
            "text": "These materials have been developed by members of the teaching team at the  Harvard Chan Bioinformatics Core (HBC) . These are open access materials distributed under the terms of the  Creative Commons Attribution license  (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.   Some materials used in these lessons were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the  Creative Commons Attribution license  (CC BY 4.0).", 
            "title": "Dataset"
        }, 
        {
            "location": "/01_the_filesystem/", 
            "text": "Learning Objectives\n\n\n\n\nHow do you access the shell?\n\n\nHow do you use it?\n\n\nGetting around the Unix file system\n\n\nlooking at files\n\n\nmanipulating files\n\n\nautomating tasks\n\n\nWhat is it good for?\n\n\n\n\nSetting up\n\n\nWe will spend most of our time learning about the basics of the shell by exploring experimental data.\n\n\nSince we are going to be working with this data on our remote server, \nOrchestra 2 (O2)\n, we first need to log onto the server. After we're logged on, we will each make our own copy of the example data folder.\n\n\nLogging in\n\n\nWith Macs\n\n\nMacs have a utility application called \"\nTerminal\n\" for performing tasks on the command line (shell), both locally and on remote machines. We will be using it to log into O2.\n\n\nWith Windows\n\n\nBy default, there is no terminal for the bash shell available in the Windows OS, so you have to use a downloaded program, \"\nGit BASH\n\". Git BASH is part of the \nGit for Windows\n download, and is a shell (bash) emulator.\n\n\n\n\nYou can also use \nPutty\n to log in to remote machines from Windows computers, but it is a little more involved and has different capabilities.\n\n\n\n\nLet's log in!\n\n\nType in the following command with your username to login:\n\n\nssh username@o2.hms.harvard.edu\n\n\n\n\nYou will receive a prompt for your password, and you should type in your associated password; note that the cursor will \nnot move\n as you type in your password.\n\n\nA warning might pop up the first time you try to connect to a remote machine, type \"Yes\" or \"Y\". \n\n\nCopying example data folder\n\n\nOnce logged in, you should see the O2 icon, some news, and the command prompt: \n\n\n[rc_training10@login01 ~]$ \n\n\n\n\nThe command prompt will have some characters before it, something like \n[rc_training01@login01 ~]\n, this is telling you what the name of the computer you are working on is.\n\n\nThe first command we will type on the command prompt will be to start a so-called \"interactive session\" on O2.\n\n\n$ srun --pty -p short -t 0-12:00 --mem 8G --reservation=HBC /bin/bash\n\n\n\n\nPress enter after you type in that command. You will get a couple of messages, but in a few seconds you should get back the command prompt \n$\n; the string of characters before the command prompt, however, have changed. They should say something like \n[rc_training01@compute-a-16-73 ~]\n. \nWe will be explaining what this means in more detail later when we talk about HPC and O2.\n \n\n\nMake sure that your command prompt is now preceded by a character string that contains the word \"compute\".\n\n\n\n\nNOTE: When you run the \nsrun\n command after this workshop with your own account please use the following command (without the \n--reservation\n option and with \n-p interactive\n):\n\n\nsrun --pty -p interactive -t 0-12:00 --mem 8G /bin/bash\n\n\nThe \"reservation\" is only active for the training accounts, and only for the duration of this workshop. We will be talking in more detail about the \n-p\n option later in this workshop.\n\n\n\n\nCopy our example data folder to your home directory using the following command:\n\n\n$ cp -r /n/groups/hbctraining/unix_lesson/ .\n\n\n\n\n\n\n'cp' is the command for copy. This command required you to specify the location of the item you want to copy (/groups/hbctraining/unix_lesson/) and the location of the destination (.); please note the space between the 2 in the command. The \"-r\" is an option that modifies the copy command to do something slightly different than usual. The \".\" means \"here\", i.e. the destination location is where you currently are.\n\n\n\n\nStarting with the shell\n\n\nWe have each created our own copy of the example data folder into our home directory, \nunix_lesson\n. Let's go into the data folder and explore the data using the shell.\n\n\n$ cd unix_lesson\n\n\n\n\n\n\n'cd' stands for 'change directory'\n\n\n\n\nLet's see what is in here. Type:\n\n\n$ ls\n\n\n\n\nYou will see:\n\n\ngenomics_data  other  raw_fastq  README.txt  reference_data\n\n\n\n\n\n\nls stands for 'list' and it lists the contents of a directory.\n\n\n\n\nThere are five items listed. What types of files are they? We can use a \"modifier\" with \nls\n to get more information; this modifier is called an argument (more below).\n\n\n$ ls -F\n\ngenomics_data/  other/  raw_fastq/  README.txt  reference_data/\n\n\n\n\nAnything with a \"/\" after it is a directory. Things with a \"*\" after them are programs.  If there are no decorations after the name, it's a file.\n\n\n\n\nAll commands are essentially programs that are able to perform specific, commonly-used tasks.\n\n\n\n\nYou can also use the command:\n\n\n$ ls -l\n\n\n\n\nto see whether items in a directory are files or directories. \nls -l\n gives a lot more information too.\n\n\ntotal 124\ndrwxrwsr-x 2 mp298 mp298  78 Sep 30 10:47 genomics_data\ndrwxrwsr-x 6 mp298 mp298 107 Sep 30 10:47 other\ndrwxrwsr-x 2 mp298 mp298 228 Sep 30 10:47 raw_fastq\n-rw-rw-r-- 1 mp298 mp298 377 Sep 30 10:47 README.txt\ndrwxrwsr-x 2 mp298 mp298 238 Sep 30 10:47 reference_data\n\n\n\n\nLet's go into the raw_fastq directory and see what is in there.\n\n\n$ cd raw_fastq/\n\n$ ls -F\n\nIrrel_kd_1.subset.fq  Irrel_kd_3.subset.fq  Mov10_oe_2.subset.fq\nIrrel_kd_2.subset.fq  Mov10_oe_1.subset.fq  Mov10_oe_3.subset.fq\n\n\n\n\nAll six items in this directory have no trailing slashes, so they are all files, not folders or programs.\n\n\nArguments\n\n\nMost commands take additional arguments that control their exact behavior. For example, \n-F\n and \n-l\n are arguments to \nls\n.  The \nls\n command, like many commands, take a lot of arguments. Another useful one is \n-a\n, which shows everything, including hidden files.  How do we know what the available arguments that go with a particular command are?\n\n\nMost commonly used shell commands have a manual available in the shell. You can access the\nmanual using the \nman\n command. Try entering:\n\n\n$ man ls\n\n\n\n\nThis will open the manual page for \nls\n. Use the 'space' key to go forward and 'b' to go backwards. When you are done reading, just hit \nq\n to quit.\n\n\nCommands that are run from the shell can get extremely complicated. To see an example, open up the manual page for the \nfind\n command. No one can possibly learn all of these arguments, of course. So you will probably find yourself referring to the manual page frequently.\n\n\n\n\nIf the manual page within the terminal is hard to read and traverse, the manual exists online, use your web searching powers to get it! In addition to the arguments, you can also find good examples online; Google is your friend.\n\n\n\n\nThe Unix directory file structure (a.k.a. where am I?)\n\n\nAs you've already just seen, you can move around in different directories or folders at the command line. Why would you want to do this, rather than just navigating around the normal way using a GUI (GUI = Graphical User Interface, pronounced like \"gooey\").\n\n\nMoving around the file system\n\n\nLet's practice moving around a bit.\n\n\nWe're going to work in that \nunix_lesson\n directory.\n\n\nFirst we did something like go to the folder of our username. Then we opened \nunix_lesson\n then \nraw_fastq\n\n\nLike on any computer you have used before the file structure within unix is hierarchical, like an upside down tree with root (/) as the starting point of the tree-like structure:\n\n\n\n\nThat root (/) is often also called the 'top' level.\n\n\nWhen you log in to a remote computer you are on one of the branches of that tree, your home directory (e.g. /home/username)\n\n\n\n\nOn mac OS, which is a UNIX-based OS, the root level is also \"/\". On a windows OS, it is drive specific; generally \"C:\\\" is considered root, but it changes to \"D:/\", if you are on that drive.\n\n\n\n\nNow let's go do that same navigation at the command line.\n\n\nType:\n\n\n$ cd\n\n\n\n\n\n\nThis puts you in your home directory. No matter where you are in the directory system, \ncd\n will always bring you back to your home directory.\n\n\n\n\nNow using \ncd\n and \nls\n, go in to the \nunix_lesson\n directory and list its contents. Now go into the \nraw_fastq\n directory, and list its contents.\n\n\nLet's also check to see where we are. Sometimes when we're wandering around in the file system, it's easy to lose track of where we are. The command that tells you this is:\n\n\n$ pwd\n\n\n\n\n\n\nThis stands for 'print working directory'. i.e. the directory you're currently working in.\n\n\n\n\nWhat if we want to move back up and out of the \nraw_fastq\n directory? Can we just type \ncd unix_lesson\n? Try it and see what happens.\n\n\nTo go 'back up a level' we can use \n..\n\n\nType:\n\n\n$ cd ..\n\n\n\n\nNow do \nls\n and \npwd\n. \n\n\n\n\n..\n denotes parent directory, and you can use it anywhere in the system to go back to the parent directory. Can you think of an example when this won't work?\n\n\n\n\nFinally, there is handy command that can help you see the structure of any directory, namely \ntree\n.\n\n\n#Ensure that you are in your unix_lesson directory and run the following command\n\n$ tree\n\n\n\n\nExamining the contents of other directories\n\n\nBy default, the \nls\n commands lists the contents of the working directory (i.e. the directory you are in). You can always find the directory you are in using the \npwd\n command. However, you can also give \nls\n the names of other directories to view. Navigate to the home directory if you are not already there.\n\n\nType:\n\n\n$ cd\n\n\n\n\nThen enter the command:\n\n\n$ ls unix_lesson/\n\n\n\n\nThis will list the contents of the \nunix_lesson\n directory without you having to navigate there.\n\n\nThe \ncd\n command works in a similar way.\n\n\n$ cd unix_lesson/raw_fastq/\n$ pwd\n\n\n\n\nYou should now be in \nraw_fastq\n and you got there without having to go through the intermediate directory. \n\n\n\n\nIf you are aware of the directory structure, you can string together as long a list as you like.\n\n\n\n\n\n\nExercise\n\n\nList the \nMov10_oe_1.subset.fq\n file from your home directory without changing directories\n\n\n\n\nFull vs. Relative Paths\n\n\nThe \ncd\n command takes an argument which is the directory name. Directories can be specified using either a \nrelative path\n or a \nfull path\n. As we know, the directories on the computer are arranged into a hierarchy. The full path tells you where a directory is in that hierarchy. Navigate to the home directory (\ncd\n). Now, enter the \npwd\n command and you should see:\n\n\n$ pwd\n\n\n\n\n/home/username\n\n\n\n\nwhich is the full path for your home directory. This tells you that you are in a directory called \nusername\n, which sits inside a directory called \nhome\n which sits inside the very top directory in the hierarchy, the \nroot directory\n. So, to summarize: \nusername\n is a directory in \nhome\n which is a directory in \n/\n.\n\n\nNow enter the following command:\n\n\n$ cd /home/username/unix_lesson/raw_fastq/\n\n\n\n\nThis jumps to \nraw_fastq\n. Now go back to the home directory (\ncd\n). We saw\nearlier that the command:\n\n\n$ cd unix_lesson/raw_fastq/\n\n\n\n\nhad the same effect - it took us to the \nraw_fastq\n directory. But, instead of specifying the full path (\n/home/username/unix_lesson/raw_fastq\n), we specified a \nrelative path\n. In other words, we specified the path \nrelative to our current working directory\n. \n\n\nA full path always starts with a \n/\n, a relative path does not.\n\n\nA relative path is like getting directions from someone on the street. They tell you to \"go right at the Stop sign, and then turn left on Main Street\". That works great if you're standing there together, but not so well if you're trying to tell someone how to get there from another country. A full path is like GPS coordinates. It tells you exactly where something is no matter where you are right now.\n\n\nYou can usually use either a full path or a relative path depending on what is most convenient. If we are in the home directory, it is more convenient to just enter the relative path since it involves less typing.\n\n\nOver time, it will become easier for you to keep a mental note of the structure of the directories that you are using and how to quickly navigate among them.\n\n\n\n\nExercise\n\n\nChange directories to \n/home/username/unix_lesson/raw_fastq/\n, and list the contents of \nunix_lesson/other\n without changing directories again.\n\n\n\n\nSaving time with tab completion, wildcards and other shortcuts\n\n\nTab completion\n\n\nNavigate to the home directory. Typing out directory names can waste a lot of time. When you start typing out the name of a directory, then hit the tab key, the shell will try to fill in the rest of the directory name. For example, type \ncd\n to get back to your home directly, then enter:\n\n\n$ cd uni\ntab\n\n\n\n\n\nThe shell will fill in the rest of the directory name for \nunix_lesson\n. Now go to \nunix_lesson/raw_fastq\n and \n\n\n$ ls Mov10_oe_\ntab\ntab\n\n\n\n\n\nWhen you hit the first tab, nothing happens. The reason is that there are multiple directories in the home directory which start with \nMov10_oe_\n. Thus, the shell does not know which one to fill in. When you hit tab again, the shell will list the possible choices.\n\n\nTab completion can also fill in the names of commands. For example, enter \ne\ntab\ntab\n. You will see the name of every command that starts with an \ne\n. One of those is \necho\n. If you enter \nec\ntab\n you will see that tab completion works. \n\n\n\n\nTab completion is your friend!\n It helps prevent spelling mistakes, and speeds up the process of typing in the full command.\n\n\n\n\nWild cards\n\n\nNavigate to the \n~/unix_lesson/raw_fastq\n directory. This directory contains FASTQ files from a next-generation sequencing dataset. \n\n\nThe '*' character is a shortcut for \"everything\". Thus, if you enter \nls *\n, you will see all of the contents of a given directory. Now try this command:\n\n\n$ ls *fq\n\n\n\n\nThis lists every file that ends with a \nfq\n. This command:\n\n\n$ ls /usr/bin/*.sh\n\n\n\n\nLists every file in \n/usr/bin\n that ends in the characters \n.sh\n.\n\n\n$ ls Mov10*fq\n\n\n\n\nlists only the files that begin with 'Mov10' and end with 'fq'\n\n\nSo how does this actually work? The shell (bash) considers an asterisk \"*\" to be a wildcard character that can be used to substitute for any other single character or a string of characters. \n\n\n\n\nAn asterisk/star is only one of the many wildcards in UNIX, but this is the most powerful one and we will be using this one the most for our exercises.\n\n\n\n\n\n\nExercise\n\n\nDo each of the following using a single \nls\n command without\nnavigating to a different directory.\n\n\n\n\nList all of the files in \n/bin\n that start with the letter 'c'\n\n\nList all of the files in \n/bin\n that contain the letter 'a'\n\n\nList all of the files in \n/bin\n that end with the letter 'o'\n\n\n\n\nBONUS: List all of the files in \n/bin\n that contain the letter 'a' or 'c'.\n\n\n\n\nShortcuts\n\n\nThere are some shortcuts which you should know about. Dealing with the\nhome directory is very common. So, in the shell the tilde character,\n\"~\", is a shortcut for your home directory. Navigate to the \nraw_fastq\n\ndirectory:\n\n\n$ cd\n\n\n\n\n$ cd unix_lesson/raw_fastq\n\n\n\n\nThen enter the command:\n\n\n$ ls ~\n\n\n\n\nThis prints the contents of your home directory, without you having to type the full path because the tilde \"~\" is equivalent to \"/home/username\".\n\n\nAnother shortcut is the \"..\":\n\n\n$ ls ..\n\n\n\n\nThe shortcut \n..\n always refers to the directory above your current directory. So, it prints the contents of the \nunix_lesson\n. You can chain these together, so:\n\n\n$ ls ../..\n\n\n\n\nprints the contents of \n/home/username\n which is your home directory. \n\n\nFinally, the special directory \n.\n always refers to your current directory. So, \nls\n, \nls .\n, and \nls ././././.\n all do the same thing, they print the contents of the current directory. This may seem like a useless shortcut right now, but we used it earlier when we copied over the data to our home directory.\n\n\nTo summarize, while you are in your home directory, the commands \nls ~\n, \nls ~/.\n, and \nls /home/username\n all do exactly the same thing. These shortcuts are not necessary, but they are really convenient!\n\n\nCommand History\n\n\nYou can easily access previous commands.  Hit the up arrow. Hit it again.  You can step backwards through your command history. The down arrow takes your forwards in the command history.\n\n\n'Ctrl-r' will do a reverse-search through your command history.  This\nis very useful.\n\n\nYou can also review your recent commands with the \nhistory\n command.  Just enter:\n\n\n$ history\n\n\n\n\nto see a numbered list of recent commands, including this just issues\n\nhistory\n command. \n\n\n\n\nOnly a certain number of commands are stored and displayed with \nhistory\n, there is a way to modify this to store a different number.\n\n\n\n\nOther handy command-related shortcuts\n\n\n\n\nCtrl + C\n will cancel the command you are writing, and give you a fresh prompt.\n\n\nCtrl + A\n will bring you to the start of the command you are writing.\n\n\nCtrl + E\n will bring you to the end of the command.\n\n\n\n\nExamining Files\n\n\nWe now know how to move around the file system and look at the\ncontents of directories, but how do we look at the contents of files?\n\n\nThe easiest way to examine a file is to just print out all of the\ncontents using the command \ncat\n. Print the contents of \nunix_lesson/other/sequences.fa\n by entering the following command:\n\n\n$ cat ~/unix_lesson/other/sequences.fa\n\n\n\n\nThis prints out the all the contents of \nsequences.fa\n to the screen.\n\n\n\n\ncat\n stands for catenate; it has many uses and printing the contents of a files onto the terminal is one of them.\n\n\n\n\nWhat does this file contain?\n\n\ncat\n is a terrific command, but when the file is really big, it can be annoying to use. The command, \nless\n, is useful for this case. Let's take a look at the raw_fastq files. These files are quite large, so we probably do not want to use the \ncat\n command to look at them. Instead, we can use the \nless\n command. \n\n\nMove back to our \nraw_fastq\n directory and enter the following command:\n\n\nless Mov10_oe_1.subset.fq\n\n\n\n\nWe will explore FASTQ files in more detail later, but notice that FASTQ files have four lines of data associated with every sequence read. Not only is there a header line and the nucleotide sequence, similar to a FASTA file, but FASTQ files also contain quality information for each nucleotide in the sequence. \n\n\nThe \nless\n command opens the file, and lets you navigate through it. The keys used to move around the file are identical to the \nman\n command.\n\n\nShortcuts for \nless\n\n\n\n\n\n\n\n\nkey\n\n\naction\n\n\n\n\n\n\n\n\n\n\nSPACE\n\n\nto go forward\n\n\n\n\n\n\nb\n\n\nto go backwards\n\n\n\n\n\n\ng\n\n\nto go to the beginning\n\n\n\n\n\n\nG\n\n\nto go to the end\n\n\n\n\n\n\nq\n\n\nto quit\n\n\n\n\n\n\n\n\nless\n also gives you a way of searching through files. Just hit the \n/\n key to begin a search. Enter the name of the string of characters you would like to search for and hit enter. It will jump to the next location where that string is found. If you hit \n/\n then \nENTER\n, \nless\n will just repeat the previous search. \nless\n searches from the current location and works its way forward. If you are at the end of the file and search for the word \"cat\", \nless\n will not find it. You need to go to the beginning of the file and search.\n\n\nFor instance, let's search for the sequence \nGAGACCC\n in our file. You can see that we go right to that sequence and can see what it looks like. To exit hit \nq\n.\n\n\nThe \nman\n command (program) actually uses \nless\n internally and therefore uses the same keys and methods, so you can search manuals using \n/\n as well!\n\n\nThere's another way that we can look at files, and in this case, just\nlook at part of them. This can be particularly useful if we just want\nto see the beginning or end of the file, or see how it's formatted.\n\n\nThe commands are \nhead\n and \ntail\n and they just let you look at\nthe beginning and end of a file respectively.\n\n\n$ head Mov10_oe_1.subset.fq\n\n\n\n\n$ tail Mov10_oe_1.subset.fq\n\n\n\n\nThe \n-n\n option to either of these commands can be used to print the first or last \nn\n lines of a file. To print the first/last line of the file use:\n\n\n$ head -n 1 Mov10_oe_1.subset.fq\n\n$ tail -n 1 Mov10_oe_1.subset.fq\n\n\n\n\nCreating, moving, copying, and removing\n\n\nNow we can move around in the file structure, look at files, search files, redirect. But what if we want to do normal things like copy files or move them around or get rid of them. Sure we could do most of these things without the command line, but what fun would that be?! Besides it's often faster to do it at the command line, or you'll be on a remote server like Amazon where you won't have another option.\n\n\nOur raw data in this case is fastq files. We don't want to change the original files, so let's make a copy to work with.\n\n\nLets copy the file using the copy \ncp\n command. Navigate to the \nraw_fastq\n directory and enter:\n\n\n$ cp Mov10_oe_1.subset.fq Mov10_oe_1.subset-copy.fq\n\n$ ls -l\n\n\n\n\nNow \nMov10_oe_1.subset-copy.fq\n has been created as a copy of \nMov10_oe_1.subset.fq\n\n\nLet's make a 'backup' directory where we can put this file.\n\n\nThe \nmkdir\n command is used to make a directory. Just enter \nmkdir\n\nfollowed by a space, then the directory name.\n\n\n$ mkdir backup\n\n\n\n\n\n\nFile/directory/program names with spaces in them do not work in unix, use characters like hyphens or underscores instead.\n\n\n\n\nWe can now move our backed up file in to this directory. We can move files around using the command \nmv\n. Enter this command:\n\n\n$ mv *copy.fq backup\n\n\n\n\n$ ls -l backup\n\n-rw-rw-r-- 1 mp298 mp298 75706556 Sep 30 13:56 Mov10_oe_1.subset-copy.fq\n\n\n\n\nThe \nmv\n command is also how you rename files. Since this file is so\nimportant, let's rename it:\n\n\n$ cd backup\n\n$ mv Mov10_oe_1.subset-copy.fq Mov10_oe_1.subset-backup.fq\n\n$ ls\n\nMov10_oe_1.subset-backup.fq\n\n\n\n\nFinally, we decided this was silly and want to start over.\n\n\n$ cd ..\n\n$ rm backup/Mov*\n\n\n\n\n\n\nThe \nrm\n file permanently removes the file. Be careful with this command. The shell doesn't\njust nicely put the files in the Trash. They're really gone.\n\n\nSame with moving and renaming files. It will \nnot\n ask you if you are sure that you want to \"replace existing file\". You can use \nrm -i\n if you want it to ask before deleting the file(s).\n\n\n\n\nWe really don't need these backup directories, so, let's delete both. By default, \nrm\n, will NOT delete directories, but you use the \n-r\n flag if you are sure that you want to delete the directories and everything within them. To be safe, let's use it with the \n-i\n flag.\n\n\n$ rm -ri backup_ref_data/ backup_fastq/ \n\n\n\n\n\n\n-r\n: recursive, commonly used as an option when working with directories, e.g. with \ncp\n. \n\n\n-i\n: prompt before every removal.\n\n\n\n\nCommands, options, and keystrokes covered\n\n\nbash\ncd\nls\nman\npwd\n~           # home dir\n.           # current dir\n..          # parent dir\n*           # wildcard\necho\nctrl + c    # cancel current command\nctrl + a    # start of line\nctrl + e    # end of line\nhistory\ncat\nless\nhead\ntail\ncp\nmdkir\nmv\nrm\n\n\n\n\nInformation on the shell\n\n\nshell cheat sheets:\n\n\n \nhttp://fosswire.com/post/2007/08/unixlinux-command-cheat-sheet/\n\n\n \nhttps://github.com/swcarpentry/boot-camps/blob/master/shell/shell_cheatsheet.md\n\n\nExplain shell - a web site where you can see what the different components of\na shell command are doing.\n\n\n \nhttp://explainshell.com\n\n\n \nhttp://www.commandlinefu.com\n\n\nSoftware Carpentry tutorial: \nThe Unix shell\n\n\nGeneral help:\n- http://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO.html\n- man bash\n- Google - if you don't know how to do something, try Googling it. Other people\nhave probably had the same question.\n- Learn by doing. There's no real other way to learn this than by trying it\nout.  Write your next paper in vim (really emacs or vi), open pdfs from\nthe command line, automate something you don't really need to automate.\n\n\n\n\nThis lesson has been developed by members of the teaching team at the \nHarvard Chan Bioinformatics Core (HBC)\n. These are open access materials distributed under the terms of the \nCreative Commons Attribution license\n (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\n\n\n\nThe materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the \nCreative Commons Attribution license\n (CC BY 4.0).\n\n\nAdapted from the lesson by Tracy Teal. Original contributors: Paul Wilson, Milad Fatenejad, Sasha Wood and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Introduction to the shell"
        }, 
        {
            "location": "/01_the_filesystem/#learning-objectives", 
            "text": "How do you access the shell?  How do you use it?  Getting around the Unix file system  looking at files  manipulating files  automating tasks  What is it good for?", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/01_the_filesystem/#setting-up", 
            "text": "We will spend most of our time learning about the basics of the shell by exploring experimental data.  Since we are going to be working with this data on our remote server,  Orchestra 2 (O2) , we first need to log onto the server. After we're logged on, we will each make our own copy of the example data folder.", 
            "title": "Setting up"
        }, 
        {
            "location": "/01_the_filesystem/#logging-in", 
            "text": "With Macs  Macs have a utility application called \" Terminal \" for performing tasks on the command line (shell), both locally and on remote machines. We will be using it to log into O2.  With Windows  By default, there is no terminal for the bash shell available in the Windows OS, so you have to use a downloaded program, \" Git BASH \". Git BASH is part of the  Git for Windows  download, and is a shell (bash) emulator.   You can also use  Putty  to log in to remote machines from Windows computers, but it is a little more involved and has different capabilities.", 
            "title": "Logging in"
        }, 
        {
            "location": "/01_the_filesystem/#lets-log-in", 
            "text": "Type in the following command with your username to login:  ssh username@o2.hms.harvard.edu  You will receive a prompt for your password, and you should type in your associated password; note that the cursor will  not move  as you type in your password.  A warning might pop up the first time you try to connect to a remote machine, type \"Yes\" or \"Y\".", 
            "title": "Let's log in!"
        }, 
        {
            "location": "/01_the_filesystem/#copying-example-data-folder", 
            "text": "Once logged in, you should see the O2 icon, some news, and the command prompt:   [rc_training10@login01 ~]$   The command prompt will have some characters before it, something like  [rc_training01@login01 ~] , this is telling you what the name of the computer you are working on is.  The first command we will type on the command prompt will be to start a so-called \"interactive session\" on O2.  $ srun --pty -p short -t 0-12:00 --mem 8G --reservation=HBC /bin/bash  Press enter after you type in that command. You will get a couple of messages, but in a few seconds you should get back the command prompt  $ ; the string of characters before the command prompt, however, have changed. They should say something like  [rc_training01@compute-a-16-73 ~] .  We will be explaining what this means in more detail later when we talk about HPC and O2.    Make sure that your command prompt is now preceded by a character string that contains the word \"compute\".   NOTE: When you run the  srun  command after this workshop with your own account please use the following command (without the  --reservation  option and with  -p interactive ):  srun --pty -p interactive -t 0-12:00 --mem 8G /bin/bash  The \"reservation\" is only active for the training accounts, and only for the duration of this workshop. We will be talking in more detail about the  -p  option later in this workshop.   Copy our example data folder to your home directory using the following command:  $ cp -r /n/groups/hbctraining/unix_lesson/ .   'cp' is the command for copy. This command required you to specify the location of the item you want to copy (/groups/hbctraining/unix_lesson/) and the location of the destination (.); please note the space between the 2 in the command. The \"-r\" is an option that modifies the copy command to do something slightly different than usual. The \".\" means \"here\", i.e. the destination location is where you currently are.", 
            "title": "Copying example data folder"
        }, 
        {
            "location": "/01_the_filesystem/#starting-with-the-shell", 
            "text": "We have each created our own copy of the example data folder into our home directory,  unix_lesson . Let's go into the data folder and explore the data using the shell.  $ cd unix_lesson   'cd' stands for 'change directory'   Let's see what is in here. Type:  $ ls  You will see:  genomics_data  other  raw_fastq  README.txt  reference_data   ls stands for 'list' and it lists the contents of a directory.   There are five items listed. What types of files are they? We can use a \"modifier\" with  ls  to get more information; this modifier is called an argument (more below).  $ ls -F\n\ngenomics_data/  other/  raw_fastq/  README.txt  reference_data/  Anything with a \"/\" after it is a directory. Things with a \"*\" after them are programs.  If there are no decorations after the name, it's a file.   All commands are essentially programs that are able to perform specific, commonly-used tasks.   You can also use the command:  $ ls -l  to see whether items in a directory are files or directories.  ls -l  gives a lot more information too.  total 124\ndrwxrwsr-x 2 mp298 mp298  78 Sep 30 10:47 genomics_data\ndrwxrwsr-x 6 mp298 mp298 107 Sep 30 10:47 other\ndrwxrwsr-x 2 mp298 mp298 228 Sep 30 10:47 raw_fastq\n-rw-rw-r-- 1 mp298 mp298 377 Sep 30 10:47 README.txt\ndrwxrwsr-x 2 mp298 mp298 238 Sep 30 10:47 reference_data  Let's go into the raw_fastq directory and see what is in there.  $ cd raw_fastq/\n\n$ ls -F\n\nIrrel_kd_1.subset.fq  Irrel_kd_3.subset.fq  Mov10_oe_2.subset.fq\nIrrel_kd_2.subset.fq  Mov10_oe_1.subset.fq  Mov10_oe_3.subset.fq  All six items in this directory have no trailing slashes, so they are all files, not folders or programs.", 
            "title": "Starting with the shell"
        }, 
        {
            "location": "/01_the_filesystem/#arguments", 
            "text": "Most commands take additional arguments that control their exact behavior. For example,  -F  and  -l  are arguments to  ls .  The  ls  command, like many commands, take a lot of arguments. Another useful one is  -a , which shows everything, including hidden files.  How do we know what the available arguments that go with a particular command are?  Most commonly used shell commands have a manual available in the shell. You can access the\nmanual using the  man  command. Try entering:  $ man ls  This will open the manual page for  ls . Use the 'space' key to go forward and 'b' to go backwards. When you are done reading, just hit  q  to quit.  Commands that are run from the shell can get extremely complicated. To see an example, open up the manual page for the  find  command. No one can possibly learn all of these arguments, of course. So you will probably find yourself referring to the manual page frequently.   If the manual page within the terminal is hard to read and traverse, the manual exists online, use your web searching powers to get it! In addition to the arguments, you can also find good examples online; Google is your friend.", 
            "title": "Arguments"
        }, 
        {
            "location": "/01_the_filesystem/#the-unix-directory-file-structure-aka-where-am-i", 
            "text": "As you've already just seen, you can move around in different directories or folders at the command line. Why would you want to do this, rather than just navigating around the normal way using a GUI (GUI = Graphical User Interface, pronounced like \"gooey\").", 
            "title": "The Unix directory file structure (a.k.a. where am I?)"
        }, 
        {
            "location": "/01_the_filesystem/#moving-around-the-file-system", 
            "text": "Let's practice moving around a bit.  We're going to work in that  unix_lesson  directory.  First we did something like go to the folder of our username. Then we opened  unix_lesson  then  raw_fastq  Like on any computer you have used before the file structure within unix is hierarchical, like an upside down tree with root (/) as the starting point of the tree-like structure:   That root (/) is often also called the 'top' level.  When you log in to a remote computer you are on one of the branches of that tree, your home directory (e.g. /home/username)   On mac OS, which is a UNIX-based OS, the root level is also \"/\". On a windows OS, it is drive specific; generally \"C:\\\" is considered root, but it changes to \"D:/\", if you are on that drive.   Now let's go do that same navigation at the command line.  Type:  $ cd   This puts you in your home directory. No matter where you are in the directory system,  cd  will always bring you back to your home directory.   Now using  cd  and  ls , go in to the  unix_lesson  directory and list its contents. Now go into the  raw_fastq  directory, and list its contents.  Let's also check to see where we are. Sometimes when we're wandering around in the file system, it's easy to lose track of where we are. The command that tells you this is:  $ pwd   This stands for 'print working directory'. i.e. the directory you're currently working in.   What if we want to move back up and out of the  raw_fastq  directory? Can we just type  cd unix_lesson ? Try it and see what happens.  To go 'back up a level' we can use  ..  Type:  $ cd ..  Now do  ls  and  pwd .    ..  denotes parent directory, and you can use it anywhere in the system to go back to the parent directory. Can you think of an example when this won't work?   Finally, there is handy command that can help you see the structure of any directory, namely  tree .  #Ensure that you are in your unix_lesson directory and run the following command\n\n$ tree", 
            "title": "Moving around the file system"
        }, 
        {
            "location": "/01_the_filesystem/#examining-the-contents-of-other-directories", 
            "text": "By default, the  ls  commands lists the contents of the working directory (i.e. the directory you are in). You can always find the directory you are in using the  pwd  command. However, you can also give  ls  the names of other directories to view. Navigate to the home directory if you are not already there.  Type:  $ cd  Then enter the command:  $ ls unix_lesson/  This will list the contents of the  unix_lesson  directory without you having to navigate there.  The  cd  command works in a similar way.  $ cd unix_lesson/raw_fastq/\n$ pwd  You should now be in  raw_fastq  and you got there without having to go through the intermediate directory.    If you are aware of the directory structure, you can string together as long a list as you like.    Exercise  List the  Mov10_oe_1.subset.fq  file from your home directory without changing directories", 
            "title": "Examining the contents of other directories"
        }, 
        {
            "location": "/01_the_filesystem/#full-vs-relative-paths", 
            "text": "The  cd  command takes an argument which is the directory name. Directories can be specified using either a  relative path  or a  full path . As we know, the directories on the computer are arranged into a hierarchy. The full path tells you where a directory is in that hierarchy. Navigate to the home directory ( cd ). Now, enter the  pwd  command and you should see:  $ pwd  /home/username  which is the full path for your home directory. This tells you that you are in a directory called  username , which sits inside a directory called  home  which sits inside the very top directory in the hierarchy, the  root directory . So, to summarize:  username  is a directory in  home  which is a directory in  / .  Now enter the following command:  $ cd /home/username/unix_lesson/raw_fastq/  This jumps to  raw_fastq . Now go back to the home directory ( cd ). We saw\nearlier that the command:  $ cd unix_lesson/raw_fastq/  had the same effect - it took us to the  raw_fastq  directory. But, instead of specifying the full path ( /home/username/unix_lesson/raw_fastq ), we specified a  relative path . In other words, we specified the path  relative to our current working directory .   A full path always starts with a  / , a relative path does not.  A relative path is like getting directions from someone on the street. They tell you to \"go right at the Stop sign, and then turn left on Main Street\". That works great if you're standing there together, but not so well if you're trying to tell someone how to get there from another country. A full path is like GPS coordinates. It tells you exactly where something is no matter where you are right now.  You can usually use either a full path or a relative path depending on what is most convenient. If we are in the home directory, it is more convenient to just enter the relative path since it involves less typing.  Over time, it will become easier for you to keep a mental note of the structure of the directories that you are using and how to quickly navigate among them.   Exercise  Change directories to  /home/username/unix_lesson/raw_fastq/ , and list the contents of  unix_lesson/other  without changing directories again.", 
            "title": "Full vs. Relative Paths"
        }, 
        {
            "location": "/01_the_filesystem/#saving-time-with-tab-completion-wildcards-and-other-shortcuts", 
            "text": "", 
            "title": "Saving time with tab completion, wildcards and other shortcuts"
        }, 
        {
            "location": "/01_the_filesystem/#tab-completion", 
            "text": "Navigate to the home directory. Typing out directory names can waste a lot of time. When you start typing out the name of a directory, then hit the tab key, the shell will try to fill in the rest of the directory name. For example, type  cd  to get back to your home directly, then enter:  $ cd uni tab   The shell will fill in the rest of the directory name for  unix_lesson . Now go to  unix_lesson/raw_fastq  and   $ ls Mov10_oe_ tab tab   When you hit the first tab, nothing happens. The reason is that there are multiple directories in the home directory which start with  Mov10_oe_ . Thus, the shell does not know which one to fill in. When you hit tab again, the shell will list the possible choices.  Tab completion can also fill in the names of commands. For example, enter  e tab tab . You will see the name of every command that starts with an  e . One of those is  echo . If you enter  ec tab  you will see that tab completion works.    Tab completion is your friend!  It helps prevent spelling mistakes, and speeds up the process of typing in the full command.", 
            "title": "Tab completion"
        }, 
        {
            "location": "/01_the_filesystem/#wild-cards", 
            "text": "Navigate to the  ~/unix_lesson/raw_fastq  directory. This directory contains FASTQ files from a next-generation sequencing dataset.   The '*' character is a shortcut for \"everything\". Thus, if you enter  ls * , you will see all of the contents of a given directory. Now try this command:  $ ls *fq  This lists every file that ends with a  fq . This command:  $ ls /usr/bin/*.sh  Lists every file in  /usr/bin  that ends in the characters  .sh .  $ ls Mov10*fq  lists only the files that begin with 'Mov10' and end with 'fq'  So how does this actually work? The shell (bash) considers an asterisk \"*\" to be a wildcard character that can be used to substitute for any other single character or a string of characters.    An asterisk/star is only one of the many wildcards in UNIX, but this is the most powerful one and we will be using this one the most for our exercises.    Exercise  Do each of the following using a single  ls  command without\nnavigating to a different directory.   List all of the files in  /bin  that start with the letter 'c'  List all of the files in  /bin  that contain the letter 'a'  List all of the files in  /bin  that end with the letter 'o'   BONUS: List all of the files in  /bin  that contain the letter 'a' or 'c'.", 
            "title": "Wild cards"
        }, 
        {
            "location": "/01_the_filesystem/#shortcuts", 
            "text": "There are some shortcuts which you should know about. Dealing with the\nhome directory is very common. So, in the shell the tilde character,\n\"~\", is a shortcut for your home directory. Navigate to the  raw_fastq \ndirectory:  $ cd  $ cd unix_lesson/raw_fastq  Then enter the command:  $ ls ~  This prints the contents of your home directory, without you having to type the full path because the tilde \"~\" is equivalent to \"/home/username\".  Another shortcut is the \"..\":  $ ls ..  The shortcut  ..  always refers to the directory above your current directory. So, it prints the contents of the  unix_lesson . You can chain these together, so:  $ ls ../..  prints the contents of  /home/username  which is your home directory.   Finally, the special directory  .  always refers to your current directory. So,  ls ,  ls . , and  ls ././././.  all do the same thing, they print the contents of the current directory. This may seem like a useless shortcut right now, but we used it earlier when we copied over the data to our home directory.  To summarize, while you are in your home directory, the commands  ls ~ ,  ls ~/. , and  ls /home/username  all do exactly the same thing. These shortcuts are not necessary, but they are really convenient!", 
            "title": "Shortcuts"
        }, 
        {
            "location": "/01_the_filesystem/#command-history", 
            "text": "You can easily access previous commands.  Hit the up arrow. Hit it again.  You can step backwards through your command history. The down arrow takes your forwards in the command history.  'Ctrl-r' will do a reverse-search through your command history.  This\nis very useful.  You can also review your recent commands with the  history  command.  Just enter:  $ history  to see a numbered list of recent commands, including this just issues history  command.    Only a certain number of commands are stored and displayed with  history , there is a way to modify this to store a different number.   Other handy command-related shortcuts   Ctrl + C  will cancel the command you are writing, and give you a fresh prompt.  Ctrl + A  will bring you to the start of the command you are writing.  Ctrl + E  will bring you to the end of the command.", 
            "title": "Command History"
        }, 
        {
            "location": "/01_the_filesystem/#examining-files", 
            "text": "We now know how to move around the file system and look at the\ncontents of directories, but how do we look at the contents of files?  The easiest way to examine a file is to just print out all of the\ncontents using the command  cat . Print the contents of  unix_lesson/other/sequences.fa  by entering the following command:  $ cat ~/unix_lesson/other/sequences.fa  This prints out the all the contents of  sequences.fa  to the screen.   cat  stands for catenate; it has many uses and printing the contents of a files onto the terminal is one of them.   What does this file contain?  cat  is a terrific command, but when the file is really big, it can be annoying to use. The command,  less , is useful for this case. Let's take a look at the raw_fastq files. These files are quite large, so we probably do not want to use the  cat  command to look at them. Instead, we can use the  less  command.   Move back to our  raw_fastq  directory and enter the following command:  less Mov10_oe_1.subset.fq  We will explore FASTQ files in more detail later, but notice that FASTQ files have four lines of data associated with every sequence read. Not only is there a header line and the nucleotide sequence, similar to a FASTA file, but FASTQ files also contain quality information for each nucleotide in the sequence.   The  less  command opens the file, and lets you navigate through it. The keys used to move around the file are identical to the  man  command.  Shortcuts for  less     key  action      SPACE  to go forward    b  to go backwards    g  to go to the beginning    G  to go to the end    q  to quit     less  also gives you a way of searching through files. Just hit the  /  key to begin a search. Enter the name of the string of characters you would like to search for and hit enter. It will jump to the next location where that string is found. If you hit  /  then  ENTER ,  less  will just repeat the previous search.  less  searches from the current location and works its way forward. If you are at the end of the file and search for the word \"cat\",  less  will not find it. You need to go to the beginning of the file and search.  For instance, let's search for the sequence  GAGACCC  in our file. You can see that we go right to that sequence and can see what it looks like. To exit hit  q .  The  man  command (program) actually uses  less  internally and therefore uses the same keys and methods, so you can search manuals using  /  as well!  There's another way that we can look at files, and in this case, just\nlook at part of them. This can be particularly useful if we just want\nto see the beginning or end of the file, or see how it's formatted.  The commands are  head  and  tail  and they just let you look at\nthe beginning and end of a file respectively.  $ head Mov10_oe_1.subset.fq  $ tail Mov10_oe_1.subset.fq  The  -n  option to either of these commands can be used to print the first or last  n  lines of a file. To print the first/last line of the file use:  $ head -n 1 Mov10_oe_1.subset.fq\n\n$ tail -n 1 Mov10_oe_1.subset.fq", 
            "title": "Examining Files"
        }, 
        {
            "location": "/01_the_filesystem/#creating-moving-copying-and-removing", 
            "text": "Now we can move around in the file structure, look at files, search files, redirect. But what if we want to do normal things like copy files or move them around or get rid of them. Sure we could do most of these things without the command line, but what fun would that be?! Besides it's often faster to do it at the command line, or you'll be on a remote server like Amazon where you won't have another option.  Our raw data in this case is fastq files. We don't want to change the original files, so let's make a copy to work with.  Lets copy the file using the copy  cp  command. Navigate to the  raw_fastq  directory and enter:  $ cp Mov10_oe_1.subset.fq Mov10_oe_1.subset-copy.fq\n\n$ ls -l  Now  Mov10_oe_1.subset-copy.fq  has been created as a copy of  Mov10_oe_1.subset.fq  Let's make a 'backup' directory where we can put this file.  The  mkdir  command is used to make a directory. Just enter  mkdir \nfollowed by a space, then the directory name.  $ mkdir backup   File/directory/program names with spaces in them do not work in unix, use characters like hyphens or underscores instead.   We can now move our backed up file in to this directory. We can move files around using the command  mv . Enter this command:  $ mv *copy.fq backup  $ ls -l backup\n\n-rw-rw-r-- 1 mp298 mp298 75706556 Sep 30 13:56 Mov10_oe_1.subset-copy.fq  The  mv  command is also how you rename files. Since this file is so\nimportant, let's rename it:  $ cd backup\n\n$ mv Mov10_oe_1.subset-copy.fq Mov10_oe_1.subset-backup.fq\n\n$ ls\n\nMov10_oe_1.subset-backup.fq  Finally, we decided this was silly and want to start over.  $ cd ..\n\n$ rm backup/Mov*   The  rm  file permanently removes the file. Be careful with this command. The shell doesn't\njust nicely put the files in the Trash. They're really gone.  Same with moving and renaming files. It will  not  ask you if you are sure that you want to \"replace existing file\". You can use  rm -i  if you want it to ask before deleting the file(s).   We really don't need these backup directories, so, let's delete both. By default,  rm , will NOT delete directories, but you use the  -r  flag if you are sure that you want to delete the directories and everything within them. To be safe, let's use it with the  -i  flag.  $ rm -ri backup_ref_data/ backup_fastq/    -r : recursive, commonly used as an option when working with directories, e.g. with  cp .   -i : prompt before every removal.", 
            "title": "Creating, moving, copying, and removing"
        }, 
        {
            "location": "/01_the_filesystem/#commands-options-and-keystrokes-covered", 
            "text": "bash\ncd\nls\nman\npwd\n~           # home dir\n.           # current dir\n..          # parent dir\n*           # wildcard\necho\nctrl + c    # cancel current command\nctrl + a    # start of line\nctrl + e    # end of line\nhistory\ncat\nless\nhead\ntail\ncp\nmdkir\nmv\nrm", 
            "title": "Commands, options, and keystrokes covered"
        }, 
        {
            "location": "/01_the_filesystem/#information-on-the-shell", 
            "text": "shell cheat sheets:    http://fosswire.com/post/2007/08/unixlinux-command-cheat-sheet/    https://github.com/swcarpentry/boot-camps/blob/master/shell/shell_cheatsheet.md  Explain shell - a web site where you can see what the different components of\na shell command are doing.    http://explainshell.com    http://www.commandlinefu.com  Software Carpentry tutorial:  The Unix shell  General help:\n- http://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO.html\n- man bash\n- Google - if you don't know how to do something, try Googling it. Other people\nhave probably had the same question.\n- Learn by doing. There's no real other way to learn this than by trying it\nout.  Write your next paper in vim (really emacs or vi), open pdfs from\nthe command line, automate something you don't really need to automate.   This lesson has been developed by members of the teaching team at the  Harvard Chan Bioinformatics Core (HBC) . These are open access materials distributed under the terms of the  Creative Commons Attribution license  (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.   The materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the  Creative Commons Attribution license  (CC BY 4.0).  Adapted from the lesson by Tracy Teal. Original contributors: Paul Wilson, Milad Fatenejad, Sasha Wood and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Information on the shell"
        }, 
        {
            "location": "/02_searching_files/", 
            "text": "Approximate time: 60 minutes\n\n\nLearning objectives\n\n\n\n\nLearn how to search for characters or patterns in a text file using the \ngrep\n command\n\n\nLearn how to write to file and append to file using output redirection\n\n\nExplore how to use the pipe (\n|\n) character to chain together commands\n\n\n\n\nSearching files\n\n\nWe went over how to search within a file using \nless\n. We can also\nsearch within files without even opening them, using \ngrep\n. Grep is a command-line\nutility for searching plain-text data sets for lines matching a pattern or regular expression (regex).\nLet's give it a try!\n\n\nWe are going to practice searching with \ngrep\n using our FASTQ files, which contain the sequencing reads (nucleotide sequences) output from a sequencing facility. Each sequencing read in a FASTQ file is associated with four lines of output, with the first line (header line) always starting with an \n@\n symbol. A whole fastq record for a single read should appear similar to the following:\n\n\n@HWI-ST330:304:H045HADXX:1:1101:1111:61397\nCACTTGTAAGGGCAGGCCCCCTTCACCCTCCCGCTCCTGGGGGANNNNNNNNNNANNNCGAGGCCCTGGGGTAGAGGGNNNNNNNNNNNNNNGATCTTGG\n+\n@?@DDDDDDHHH?GH:?FCBGGB@C?DBEGIIIIAEF;FCGGI#########################################################\n\n\n\nSuppose we want to see how many reads in our file \nMov10_oe_1.subset.fq\n are \"bad\", with 10 consecutive Ns (\nNNNNNNNNNN\n).\n\n\n$ cd ~/unix_lesson/raw_fastq\n\n$ grep NNNNNNNNNN Mov10_oe_1.subset.fq\n\n\n\n\nWe get back a lot of lines.  What if we want to see the whole fastq record for each of these reads? \n\n\nWe can use the \n-B\n and \n-A\n arguments for grep to return the matched line plus one before (\n-B1\n) and two lines after (\n-A2\n). Since each record is four lines and the second line is the sequence, this should return the whole record.\n\n\n$ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_1.subset.fq\n\n\n\n\n@HWI-ST330:304:H045HADXX:1:1101:1111:61397\nCACTTGTAAGGGCAGGCCCCCTTCACCCTCCCGCTCCTGGGGGANNNNNNNNNNANNNCGAGGCCCTGGGGTAGAGGGNNNNNNNNNNNNNNGATCTTGG\n+\n@?@DDDDDDHHH?GH:?FCBGGB@C?DBEGIIIIAEF;FCGGI#########################################################\n--\n@HWI-ST330:304:H045HADXX:1:1101:1106:89824\nCACAAATCGGCTCAGGAGGCTTGTAGAAAAGCTCAGCTTGACANNNNNNNNNNNNNNNNNGNGNACGAAACNNNNGNNNNNNNNNNNNNNNNNNNGTTGG\n+\n?@@DDDDDB1@?:E?;3A:1?9?E9?\n?DGCDGBBDBF@;8DF#########################################################\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\nSearch for the sequence CTCAATGA in \nMov10_oe_1.subset.fq\n.\nIn addition to finding the sequence, have your search also return\nthe name of the sequence.\n\n\n\n\n\n\nSearch for that sequence in all Mov10 replicate fastq files.\n\n\n\n\n\n\n\n\nRedirection\n\n\nWe're excited we have all these sequences that we care about that we\njust got from the FASTQ files. That is a really important motif\nthat is going to help us answer our important question. But all those\nsequences just went whizzing by with grep. How can we capture them?\n\n\nWe can do that with something called \"redirection\". The idea is that\nwe're redirecting the output from the terminal (all the stuff that went\nwhizzing by) to something else. In this case, we want to print it\nto a file, so that we can look at it later.\n\n\nThe redirection command for writing something to file is \n.\n\n\nLet's try it out and put all the sequences that contain 'NNNNNNNNNN'\nfrom all the files into another file called \nbad_reads.txt\n.\n\n\n$ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_1.subset.fq \n bad_reads.txt\n\n\n\n\nThe prompt should sit there a little bit, and then it should look like nothing\nhappened. But you should have a new file called \nbad_reads.txt\n. \n\n\n$ ls -l\n\n\n\n\nTake a look at the file and see if it contains what you think it should. \nNOTE: If we already had a file named \nbad_reads.txt\n in our directory, it would have overwritten it without any warning.\n\n\nThe redirection command for appending something to an existing file is \n.\n\n\nIf we use \n, it will append to rather than overwrite a file.  This can be useful for saving more than one search, for example.\n\n\n$ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_2.subset.fq \n bad_reads.txt\n\n$ ls -l\n\n\n\n\nSince our \nbad_reads.txt\n file isn't a raw_fastq file, we should move it to a different location within our directory. We decide to move it to the \nother\n folder using the command \nmv\n. \n\n\n$ mv bad_reads.txt ../other/\n\n\n\n\nThere's one more useful redirection command that we're going to show, and that's called the pipe command. \n\n\nThe redirection command for using the output of a command as input for a different command is \n|\n.\n\n\nIt's probably not a key on your keyboard you use very much. What \n|\n does is take the output that went scrolling by on the terminal and runs it through another command. When it was all whizzing by before, we wished we could just slow it down and look at it, like we can with \nless\n. Well it turns out that we can! We pipe the \ngrep\n command to \nless\n or to \nhead\n to just see the first few lines.\n\n\n$ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_1.subset.fq | less\n\n\n\n\nNow we can use the arrows to scroll up and down and use \nq\n to get out.\n\n\nWe can also do count the number of lines using the \nwc\n command. \nwc\n stands for \nword count\n. It counts the number of lines, words or characters. So, we can use it to count the number of lines we're getting back from our \ngrep\n command using the \n-l\n argument. And that will magically tell us how many bad sequences we have in the file.\n\n\n$ grep NNNNNNNNNN Mov10_oe_1.subset.fq | wc -l\n\n\n\n\nThis command when used without any arguments would tell us the number of lines, words and characters in the file; the \n-l\n flag specifies that we only want the number of lines. Try it out without the \n-l\n to see the full output.\n\n\nRedirecting is not super intuitive, but it's really powerful for stringing together these different commands, so you can do whatever you need to do.\n\n\nThe philosophy behind these commands is that none of them really do anything all that impressive. BUT when you start chaining them together, you can do some really powerful things really efficiently. \nTo be able to use the shell effectively, becoming proficient with the pipe and redirection operators:  \n|\n, \n, \n is essential.\n\n\nPractice with searching and redirection (piping)\n\n\nFinally, let's use the new tools in our kit and a few new ones to examine our gene annotation file, \nchr1-hg19_genes.gtf\n, which we will be using later to find the genomic coordinates of all known exons on chromosome 1.\n\n\n$ cd ~/unix_lesson/reference_data/\n\n\n\n\nLet's explore our \nchr1-hg19_genes.gtf\n file a bit. What information does it contain?\n\n\n$ less chr1-hg19_genes.gtf\n\n\n\n\nchr1    unknown exon    14362   14829   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    14970   15038   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    15796   15947   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    16607   16765   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    16858   17055   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\n\n\n\n\n\nThe GTF file is a tab-delimited gene annotation file often used in NGS analyses. For more information on this file format, check out the \nEnsembl site\n. \n\n\n\n\nThe columns in the \nGTF file contain the genomic coordinates of gene features (exon, start_codon, stop_codon, CDS) and the gene_names, transcript_ids and protein_ids (p_id) associated with these features\n. Note that sometimes an exon can be associated with multiple different transcripts or gene isoforms. For example, \n\n\n$ grep PLEKHN1 chr1-hg19_genes.gtf | head -n 5\n\n\n\n\nThis search returns two different transcripts of the same gene, NM_001160184 and NM_032129, that contain the same exon.\n\n\nNow that we know what type of information is inside of our gtf file, let's explore our commands to answer a simple question about our data: \nhow many unique exons are present on chromosome 1 using \nchr1-hg19_genes.gtf\n?\n\n\nTo determine the number of unique exons on chromosome 1, we are going to perform a series of steps:\n\n\n1. Extract only the genomic coordinates of exon features\n2. Subset the dataset to only include the feature type and genomic location information\n3. Remove duplicate exons\n4. Count the total number of exons\n\n\n\nExtracting exon features\n\n\nWe only want the exons (not CDS or start_codon features), so let's use \ngrep\n to only keep the exon lines and pipe it to head to see what we get:\n\n\n$ grep exon chr1-hg19_genes.gtf | head\n\n\n\n\nSubsetting dataset to only keep genomic coordinates\n\n\nWe will define the uniqueness of an exon by its genomic coordinates. Therefore, we only need the genomic location (chr, start, stop, and strand) information to find the total number of unique exons. The columns corresponding to this information are 1, 4, 5, and 7. \n\n\n'cut' is a program that will extract columns from files.  It is a very good command to know.  Let's first try out the 'cut' command on a just the exonic lines to make sure we have the command correct by using multiple piped commands and looking at the first 10 lines:\n\n\n$ grep exon chr1-hg19_genes.gtf | cut -f1,4,5,7  | head\n\n\n\n\n-f1,4,5,7\n means to cut these fields (columns) from the dataset.  \n\n\nchr1    14362   14829   -\nchr1    14970   15038   -\nchr1    15796   15947   -\nchr1    16607   16765   -\nchr1    16858   17055   -\n\n\n\nThe \ncut\n command assumes our data columns are separated by tabs (i.e. tab-delimited). The \nchr1-hg19_genes.gtf\n is a tab-delimited file, so the default \ncut\n command works for us. However, data can be separated by other types of delimiters. Another common delimiter is the comma, which separates data in comma-separated value (csv) files. If your data is not tab delimited, there is a \ncut\n command argument (\n-d\n) to specify the delimiter.\n\n\nOur output looks good, so let's keep going...\n\n\nRemoving duplicate exons\n\n\nNow, we need to remove those exons that show up multiple times for different transcripts. For this, we can use a new tool, \nsort\n, to remove exons that show up more than once. We can use the \nsort\n command with the \n-u\n option to return only unique lines.\n\n\n$ grep exon chr1-hg19_genes.gtf | cut -f1,4,5,7 | sort -u | head \n\n\n\n\nDo you see a change in how the sorting has changed? By default the \nsort\n command will sort and what you can't see here is that it has removed the duplicates. How do we check this?\n\n\nCounting the total number of exons\n\n\nFirst, let's check how many lines we would have without using \nsort -u\n by piping the output to \nwc -l\n.\n\n\ngrep exon chr1-hg19_genes.gtf | cut -f1,4,5,7 | wc -l\n\n\n\n\nNow, to count how many unique exons are on chromosome 1, we will add back the \nsort -u\n and pipe the output to \nwc -l\n\n\n$ grep exon chr1-hg19_genes.gtf | cut -f1,4,5,7 | sort -u | wc -l\n\n\n\n\nWhat we did in one command up here, we could have done it in multiple steps by saving the output of each command to a file, but that would not be as efficient if all we needed was a number to work with. The intermediate files are not useful and they occupy precious space on the computer and add clutter to the file system. \n\n\nCommands, options, and keystrokes covered in this lesson\n\n\ngrep\n\n (output redirection)\n\n (output redirection, append)\n| (output redirection, pipe)\nwc\ncut\nsort\n\n\n\n\n\n\nThis lesson has been developed by members of the teaching team at the \nHarvard Chan Bioinformatics Core (HBC)\n. These are open access materials distributed under the terms of the \nCreative Commons Attribution license\n (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\n\n\n\n\n\nThe materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the \nCreative Commons Attribution license\n (CC BY 4.0).\n\n\n\n\n\n\nAdapted from the lesson by Tracy Teal. Contributors: Paul Wilson, Milad Fatenejad, Sasha Wood, and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Searching and redirection in shell"
        }, 
        {
            "location": "/02_searching_files/#learning-objectives", 
            "text": "Learn how to search for characters or patterns in a text file using the  grep  command  Learn how to write to file and append to file using output redirection  Explore how to use the pipe ( | ) character to chain together commands", 
            "title": "Learning objectives"
        }, 
        {
            "location": "/02_searching_files/#searching-files", 
            "text": "We went over how to search within a file using  less . We can also\nsearch within files without even opening them, using  grep . Grep is a command-line\nutility for searching plain-text data sets for lines matching a pattern or regular expression (regex).\nLet's give it a try!  We are going to practice searching with  grep  using our FASTQ files, which contain the sequencing reads (nucleotide sequences) output from a sequencing facility. Each sequencing read in a FASTQ file is associated with four lines of output, with the first line (header line) always starting with an  @  symbol. A whole fastq record for a single read should appear similar to the following:  @HWI-ST330:304:H045HADXX:1:1101:1111:61397\nCACTTGTAAGGGCAGGCCCCCTTCACCCTCCCGCTCCTGGGGGANNNNNNNNNNANNNCGAGGCCCTGGGGTAGAGGGNNNNNNNNNNNNNNGATCTTGG\n+\n@?@DDDDDDHHH?GH:?FCBGGB@C?DBEGIIIIAEF;FCGGI#########################################################  Suppose we want to see how many reads in our file  Mov10_oe_1.subset.fq  are \"bad\", with 10 consecutive Ns ( NNNNNNNNNN ).  $ cd ~/unix_lesson/raw_fastq\n\n$ grep NNNNNNNNNN Mov10_oe_1.subset.fq  We get back a lot of lines.  What if we want to see the whole fastq record for each of these reads?   We can use the  -B  and  -A  arguments for grep to return the matched line plus one before ( -B1 ) and two lines after ( -A2 ). Since each record is four lines and the second line is the sequence, this should return the whole record.  $ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_1.subset.fq  @HWI-ST330:304:H045HADXX:1:1101:1111:61397\nCACTTGTAAGGGCAGGCCCCCTTCACCCTCCCGCTCCTGGGGGANNNNNNNNNNANNNCGAGGCCCTGGGGTAGAGGGNNNNNNNNNNNNNNGATCTTGG\n+\n@?@DDDDDDHHH?GH:?FCBGGB@C?DBEGIIIIAEF;FCGGI#########################################################\n--\n@HWI-ST330:304:H045HADXX:1:1101:1106:89824\nCACAAATCGGCTCAGGAGGCTTGTAGAAAAGCTCAGCTTGACANNNNNNNNNNNNNNNNNGNGNACGAAACNNNNGNNNNNNNNNNNNNNNNNNNGTTGG\n+\n?@@DDDDDB1@?:E?;3A:1?9?E9? ?DGCDGBBDBF@;8DF#########################################################   Exercises    Search for the sequence CTCAATGA in  Mov10_oe_1.subset.fq .\nIn addition to finding the sequence, have your search also return\nthe name of the sequence.    Search for that sequence in all Mov10 replicate fastq files.", 
            "title": "Searching files"
        }, 
        {
            "location": "/02_searching_files/#redirection", 
            "text": "We're excited we have all these sequences that we care about that we\njust got from the FASTQ files. That is a really important motif\nthat is going to help us answer our important question. But all those\nsequences just went whizzing by with grep. How can we capture them?  We can do that with something called \"redirection\". The idea is that\nwe're redirecting the output from the terminal (all the stuff that went\nwhizzing by) to something else. In this case, we want to print it\nto a file, so that we can look at it later.  The redirection command for writing something to file is  .  Let's try it out and put all the sequences that contain 'NNNNNNNNNN'\nfrom all the files into another file called  bad_reads.txt .  $ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_1.subset.fq   bad_reads.txt  The prompt should sit there a little bit, and then it should look like nothing\nhappened. But you should have a new file called  bad_reads.txt .   $ ls -l  Take a look at the file and see if it contains what you think it should.  NOTE: If we already had a file named  bad_reads.txt  in our directory, it would have overwritten it without any warning.  The redirection command for appending something to an existing file is  .  If we use  , it will append to rather than overwrite a file.  This can be useful for saving more than one search, for example.  $ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_2.subset.fq   bad_reads.txt\n\n$ ls -l  Since our  bad_reads.txt  file isn't a raw_fastq file, we should move it to a different location within our directory. We decide to move it to the  other  folder using the command  mv .   $ mv bad_reads.txt ../other/  There's one more useful redirection command that we're going to show, and that's called the pipe command.   The redirection command for using the output of a command as input for a different command is  | .  It's probably not a key on your keyboard you use very much. What  |  does is take the output that went scrolling by on the terminal and runs it through another command. When it was all whizzing by before, we wished we could just slow it down and look at it, like we can with  less . Well it turns out that we can! We pipe the  grep  command to  less  or to  head  to just see the first few lines.  $ grep -B 1 -A 2 NNNNNNNNNN Mov10_oe_1.subset.fq | less  Now we can use the arrows to scroll up and down and use  q  to get out.  We can also do count the number of lines using the  wc  command.  wc  stands for  word count . It counts the number of lines, words or characters. So, we can use it to count the number of lines we're getting back from our  grep  command using the  -l  argument. And that will magically tell us how many bad sequences we have in the file.  $ grep NNNNNNNNNN Mov10_oe_1.subset.fq | wc -l  This command when used without any arguments would tell us the number of lines, words and characters in the file; the  -l  flag specifies that we only want the number of lines. Try it out without the  -l  to see the full output.  Redirecting is not super intuitive, but it's really powerful for stringing together these different commands, so you can do whatever you need to do.  The philosophy behind these commands is that none of them really do anything all that impressive. BUT when you start chaining them together, you can do some really powerful things really efficiently.  To be able to use the shell effectively, becoming proficient with the pipe and redirection operators:   | ,  ,   is essential.", 
            "title": "Redirection"
        }, 
        {
            "location": "/02_searching_files/#practice-with-searching-and-redirection-piping", 
            "text": "Finally, let's use the new tools in our kit and a few new ones to examine our gene annotation file,  chr1-hg19_genes.gtf , which we will be using later to find the genomic coordinates of all known exons on chromosome 1.  $ cd ~/unix_lesson/reference_data/  Let's explore our  chr1-hg19_genes.gtf  file a bit. What information does it contain?  $ less chr1-hg19_genes.gtf  chr1    unknown exon    14362   14829   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    14970   15038   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    15796   15947   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    16607   16765   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";\nchr1    unknown exon    16858   17055   .       -       .       gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS7245\";   The GTF file is a tab-delimited gene annotation file often used in NGS analyses. For more information on this file format, check out the  Ensembl site .    The columns in the  GTF file contain the genomic coordinates of gene features (exon, start_codon, stop_codon, CDS) and the gene_names, transcript_ids and protein_ids (p_id) associated with these features . Note that sometimes an exon can be associated with multiple different transcripts or gene isoforms. For example,   $ grep PLEKHN1 chr1-hg19_genes.gtf | head -n 5  This search returns two different transcripts of the same gene, NM_001160184 and NM_032129, that contain the same exon.  Now that we know what type of information is inside of our gtf file, let's explore our commands to answer a simple question about our data:  how many unique exons are present on chromosome 1 using  chr1-hg19_genes.gtf ?  To determine the number of unique exons on chromosome 1, we are going to perform a series of steps:  1. Extract only the genomic coordinates of exon features\n2. Subset the dataset to only include the feature type and genomic location information\n3. Remove duplicate exons\n4. Count the total number of exons", 
            "title": "Practice with searching and redirection (piping)"
        }, 
        {
            "location": "/02_searching_files/#extracting-exon-features", 
            "text": "We only want the exons (not CDS or start_codon features), so let's use  grep  to only keep the exon lines and pipe it to head to see what we get:  $ grep exon chr1-hg19_genes.gtf | head", 
            "title": "Extracting exon features"
        }, 
        {
            "location": "/02_searching_files/#subsetting-dataset-to-only-keep-genomic-coordinates", 
            "text": "We will define the uniqueness of an exon by its genomic coordinates. Therefore, we only need the genomic location (chr, start, stop, and strand) information to find the total number of unique exons. The columns corresponding to this information are 1, 4, 5, and 7.   'cut' is a program that will extract columns from files.  It is a very good command to know.  Let's first try out the 'cut' command on a just the exonic lines to make sure we have the command correct by using multiple piped commands and looking at the first 10 lines:  $ grep exon chr1-hg19_genes.gtf | cut -f1,4,5,7  | head  -f1,4,5,7  means to cut these fields (columns) from the dataset.    chr1    14362   14829   -\nchr1    14970   15038   -\nchr1    15796   15947   -\nchr1    16607   16765   -\nchr1    16858   17055   -  The  cut  command assumes our data columns are separated by tabs (i.e. tab-delimited). The  chr1-hg19_genes.gtf  is a tab-delimited file, so the default  cut  command works for us. However, data can be separated by other types of delimiters. Another common delimiter is the comma, which separates data in comma-separated value (csv) files. If your data is not tab delimited, there is a  cut  command argument ( -d ) to specify the delimiter.  Our output looks good, so let's keep going...", 
            "title": "Subsetting dataset to only keep genomic coordinates"
        }, 
        {
            "location": "/02_searching_files/#removing-duplicate-exons", 
            "text": "Now, we need to remove those exons that show up multiple times for different transcripts. For this, we can use a new tool,  sort , to remove exons that show up more than once. We can use the  sort  command with the  -u  option to return only unique lines.  $ grep exon chr1-hg19_genes.gtf | cut -f1,4,5,7 | sort -u | head   Do you see a change in how the sorting has changed? By default the  sort  command will sort and what you can't see here is that it has removed the duplicates. How do we check this?", 
            "title": "Removing duplicate exons"
        }, 
        {
            "location": "/02_searching_files/#counting-the-total-number-of-exons", 
            "text": "First, let's check how many lines we would have without using  sort -u  by piping the output to  wc -l .  grep exon chr1-hg19_genes.gtf | cut -f1,4,5,7 | wc -l  Now, to count how many unique exons are on chromosome 1, we will add back the  sort -u  and pipe the output to  wc -l  $ grep exon chr1-hg19_genes.gtf | cut -f1,4,5,7 | sort -u | wc -l  What we did in one command up here, we could have done it in multiple steps by saving the output of each command to a file, but that would not be as efficient if all we needed was a number to work with. The intermediate files are not useful and they occupy precious space on the computer and add clutter to the file system.   Commands, options, and keystrokes covered in this lesson  grep  (output redirection)  (output redirection, append)\n| (output redirection, pipe)\nwc\ncut\nsort   This lesson has been developed by members of the teaching team at the  Harvard Chan Bioinformatics Core (HBC) . These are open access materials distributed under the terms of the  Creative Commons Attribution license  (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.    The materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the  Creative Commons Attribution license  (CC BY 4.0).    Adapted from the lesson by Tracy Teal. Contributors: Paul Wilson, Milad Fatenejad, Sasha Wood, and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Counting the total number of exons"
        }, 
        {
            "location": "/03_vim/", 
            "text": "Approximate time: 30 min\n\n\nLearning Objectives\n\n\n\n\nLearn basic operations using the Vim text editor\n\n\n\n\nWriting files\n\n\nWe've been able to do a lot of work with files that already exist, but what if we want to write our own files. Obviously, we're not going to type in a FASTA file, but you'll see as we go, there are a lot of reasons we'll want to write/create a file or edit an existing file.\n\n\nTo create or edit files we will need to use a \ntext editor\n. When we say, \"text editor,\" we really do mean \"text\": these editors can\nonly work with plain character data, not tables, images, or any other\nmedia. The types of text editors available can generally be grouped into \ngraphical user interface (GUI) text editors\n and \ncommand-line editors\n.\n\n\nGUI text editors\n\n\nA GUI is an interface that has buttons and menus that you can click on to issue commands to the computer and you can move about the interface just by pointing and clicking. You might be familar with GUI text editors, such as \nTextWrangler\n, \nSublime\n, and \nNotepad++\n, which allow you to write and edit plain text documents. These editors often have features to easily search text, extract text, and highlight syntax from multiple programming languages. They are great tools, but since they are 'point-and-click', we cannot efficiently use them from the command line remotely on a compute cluster.\n\n\nCommand-line editors\n\n\nWhen working remotely, we need a text editor that functions from the command line interface. Within these editors, since you cannot 'point-and-click', you must navigate the interface using the arrow keys and shortcuts. \n\n\nWhile there are simpler editors available for use (i.e. \nnano\n), most computational scientists tend to favor editors that have greater functionality. Some popular editors include \nEmacs\n, \nVim\n, or a graphical editor such as \nGedit\n. These are editors which are generally available for use on high-performance compute clusters.\n\n\nIntroduction to Vim\n\n\nTo write and edit files, we're going to use a text editor called 'Vim'. Vim is a very powerful text editor, and it offers extensive text editing options. However, in this introduction we are going to focus on exploring some of the more basic functions. There is a lot of functionality that we are not going to cover during this session, but encourage you to go further as you become more comfortable using it. To help you remember some of the keyboard shortcuts that are introduced below and to allow you to explore additional functionality on your own, we have compiled a \ncheatsheet\n.\n\n\nVim Interface\n\n\nYou can create a document by calling a text editor and providing the name of the document you wish to create. Change directories to the \nunix_lesson/other\n folder and create a document using \nvim\n entitled \ndraft.txt\n:\n\n\n$ cd ~/unix_lesson/other\n\n$ vim draft.txt\n\n\n\n\nNotice the \n\"draft.txt\" [New File]\n typed at the bottom left-hand section of the screen. This tells you that you just created a new file in vim. \n\n\nVim Modes\n\n\nVim has \ntwo basic modes\n that will allow you to create documents and edit your text:   \n\n\n\n\n\n\ncommand mode (default mode):\n will allow you to save and quit the program (and execute other more advanced commands).  \n\n\n\n\n\n\ninsert (or edit) mode:\n will allow you to write and edit text\n\n\n\n\n\n\nUpon creation of a file, vim is automatically in command mode. Let's \nchange to insert mode\n by typing \ni\n. Notice the \n--INSERT--\n at the bottom left hand of the screen. Now type in a few lines of text:\n\n\n\n\nAfter you have finished typing, press \nesc\n to enter command mode. Notice the \n--INSERT--\n disappeared from the bottom of the screen.\n\n\nVim Saving and Quitting\n\n\nTo \nwrite to file (save)\n, type \n:w\n. You can see the commands you type in the bottom left-hand corner of the screen. \n\n\n\n\nAfter you have saved the file, the total number of lines and characters in the file will print out at the bottom left-hand section of the screen.\n\n\n\n\nAlternatively, we can \nwrite to file (save) and quit\n. Let's do that by typing \n:wq\n. Now, you should have exited vim and returned back to your terminal window.\n\n\nTo edit your \ndraft.txt\n document, open up the file again by calling vim and entering the file name: \nvim draft.txt\n. Change to insert mode and type a few more lines (you can move around the lines using the arrows on the keyboard). This time we decide to \nquit without saving\n by typing \n:q!\n\n\n\n\nVim Editing\n\n\nCreate the document \nspider.txt\n in vim. Enter the text as follows: \n\n\n\n\nTo make it easier to refer to distinct lines, we can add line numbers by typing \n:set number\n. \nSave the document.\n Later, if you choose to remove the line numbers you can type \n:set nonumber\n.\n\n\n\n\nWhile we cannot point and click to navigate the document, we can use the arrow keys to move around. Navigating with arrow keys can be very slow, so Vim has shortcuts (which are completely unituitive, but very useful as you get used to them over time). Check to see what mode you are currently in. While in command mode, try moving around the screen and familarizing yourself with some of these shortcuts:    \n\n\n\n\n\n\n\n\nkey\n\n\naction\n\n\n\n\n\n\n\n\n\n\ngg\n\n\nto move to top of file\n\n\n\n\n\n\nG\n\n\nto move to bottom of file\n\n\n\n\n\n\n$\n\n\nto move to end of line\n\n\n\n\n\n\n0\n\n\nto move to beginning of line\n\n\n\n\n\n\nw\n\n\nto move to next word\n\n\n\n\n\n\nb\n\n\nto move to previous word\n\n\n\n\n\n\n\n\nIn addition to shortcuts for navigation, vim also offers editing shortcuts such as:\n\n\n\n\n\n\n\n\nkey\n\n\naction\n\n\n\n\n\n\n\n\n\n\ndw\n\n\nto delete word\n\n\n\n\n\n\ndd\n\n\nto delete line\n\n\n\n\n\n\nu\n\n\nto undo\n\n\n\n\n\n\nCtrl + r\n\n\nto redo\n\n\n\n\n\n\n/\npattern\n\n\nto search for a pattern (\nn/N\n to move to next/previous match)\n\n\n\n\n\n\n:%s/\nsearch\n/\nreplace\n/g\n\n\nto search for a pattern and replace for all occurences\n\n\n\n\n\n\n\n\nPractice some of the editing shortcuts, then quit the document without saving any changes.\n\n\n\n\nExercise\n\n\nWe have covered some basic commands in vim, but practice is key for getting comfortable with the program. Let's\npractice what we just learned in a brief challenge.\n\n\n\n\nOpen \nspider.txt\n, and delete the word \"water\" from line #2.\n\n\nQuit without saving.\n\n\nOpen \nspider.txt\n again, and replace every occurrence of \"spider\" with \"unicorn\".\n\n\nDelete: \"Down came the rain.\" \n\n\nSave the file.\n\n\nUndo your previous deletion.\n\n\nRedo your previous deletion.\n\n\nDelete the first and last words from each of the lines.\n\n\nSave the file and see whether your results match your neighbors.\n\n\n\n\n\n\nOverview of vim commands\n\n\nVim modes:\n\n\n\n\n\n\n\n\nkey\n\n\naction\n\n\n\n\n\n\n\n\n\n\ni\n\n\ninsert mode - to write and edit text\n\n\n\n\n\n\nesc\n\n\ncommand mode - to issue commands / shortcuts\n\n\n\n\n\n\n\n\nSaving and quiting:\n\n\n\n\n\n\n\n\nkey\n\n\naction\n\n\n\n\n\n\n\n\n\n\n:w\n\n\nto write to file (save)\n\n\n\n\n\n\n:wq\n\n\nto write to file and quit\n\n\n\n\n\n\n:q!\n\n\nto quit without saving\n\n\n\n\n\n\n\n\nShortcuts for navigation:\n\n\n\n\n\n\n\n\nkey\n\n\naction\n\n\n\n\n\n\n\n\n\n\ngg\n\n\nto move to top of file\n\n\n\n\n\n\nG\n\n\nto move to bottom of file\n\n\n\n\n\n\n$\n\n\nto move to end of line\n\n\n\n\n\n\n0\n\n\nto move to beginning of line\n\n\n\n\n\n\nw\n\n\nto move to next word\n\n\n\n\n\n\nb\n\n\nto move to previous word\n\n\n\n\n\n\n\n\nShortcuts for editing:\n\n\n\n\n\n\n\n\nkey\n\n\naction\n\n\n\n\n\n\n\n\n\n\ndw\n\n\nto delete word\n\n\n\n\n\n\ndd\n\n\nto delete line\n\n\n\n\n\n\nu\n\n\nto undo\n\n\n\n\n\n\nCtrl + r\n\n\nto redo\n\n\n\n\n\n\n:set number\n\n\nto number lines\n\n\n\n\n\n\n:set nonumber\n\n\nto remove line numbers\n\n\n\n\n\n\n/pattern\n\n\nto search for a pattern (\nn/N\n to move to next/previous match)\n\n\n\n\n\n\n:%s/search/replace/g\n\n\nto search for a pattern and replace for all occurences\n\n\n\n\n\n\n\n\n\n\nThis lesson has been developed by members of the teaching team at the \nHarvard Chan Bioinformatics Core (HBC)\n. These are open access materials distributed under the terms of the \nCreative Commons Attribution license\n (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.", 
            "title": "Introduction to the `vim` text editor"
        }, 
        {
            "location": "/03_vim/#learning-objectives", 
            "text": "Learn basic operations using the Vim text editor", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/03_vim/#writing-files", 
            "text": "We've been able to do a lot of work with files that already exist, but what if we want to write our own files. Obviously, we're not going to type in a FASTA file, but you'll see as we go, there are a lot of reasons we'll want to write/create a file or edit an existing file.  To create or edit files we will need to use a  text editor . When we say, \"text editor,\" we really do mean \"text\": these editors can\nonly work with plain character data, not tables, images, or any other\nmedia. The types of text editors available can generally be grouped into  graphical user interface (GUI) text editors  and  command-line editors .", 
            "title": "Writing files"
        }, 
        {
            "location": "/03_vim/#gui-text-editors", 
            "text": "A GUI is an interface that has buttons and menus that you can click on to issue commands to the computer and you can move about the interface just by pointing and clicking. You might be familar with GUI text editors, such as  TextWrangler ,  Sublime , and  Notepad++ , which allow you to write and edit plain text documents. These editors often have features to easily search text, extract text, and highlight syntax from multiple programming languages. They are great tools, but since they are 'point-and-click', we cannot efficiently use them from the command line remotely on a compute cluster.", 
            "title": "GUI text editors"
        }, 
        {
            "location": "/03_vim/#command-line-editors", 
            "text": "When working remotely, we need a text editor that functions from the command line interface. Within these editors, since you cannot 'point-and-click', you must navigate the interface using the arrow keys and shortcuts.   While there are simpler editors available for use (i.e.  nano ), most computational scientists tend to favor editors that have greater functionality. Some popular editors include  Emacs ,  Vim , or a graphical editor such as  Gedit . These are editors which are generally available for use on high-performance compute clusters.", 
            "title": "Command-line editors"
        }, 
        {
            "location": "/03_vim/#introduction-to-vim", 
            "text": "To write and edit files, we're going to use a text editor called 'Vim'. Vim is a very powerful text editor, and it offers extensive text editing options. However, in this introduction we are going to focus on exploring some of the more basic functions. There is a lot of functionality that we are not going to cover during this session, but encourage you to go further as you become more comfortable using it. To help you remember some of the keyboard shortcuts that are introduced below and to allow you to explore additional functionality on your own, we have compiled a  cheatsheet .", 
            "title": "Introduction to Vim"
        }, 
        {
            "location": "/03_vim/#vim-interface", 
            "text": "You can create a document by calling a text editor and providing the name of the document you wish to create. Change directories to the  unix_lesson/other  folder and create a document using  vim  entitled  draft.txt :  $ cd ~/unix_lesson/other\n\n$ vim draft.txt  Notice the  \"draft.txt\" [New File]  typed at the bottom left-hand section of the screen. This tells you that you just created a new file in vim.", 
            "title": "Vim Interface"
        }, 
        {
            "location": "/03_vim/#vim-modes", 
            "text": "Vim has  two basic modes  that will allow you to create documents and edit your text:       command mode (default mode):  will allow you to save and quit the program (and execute other more advanced commands).      insert (or edit) mode:  will allow you to write and edit text    Upon creation of a file, vim is automatically in command mode. Let's  change to insert mode  by typing  i . Notice the  --INSERT--  at the bottom left hand of the screen. Now type in a few lines of text:   After you have finished typing, press  esc  to enter command mode. Notice the  --INSERT--  disappeared from the bottom of the screen.", 
            "title": "Vim Modes"
        }, 
        {
            "location": "/03_vim/#vim-saving-and-quitting", 
            "text": "To  write to file (save) , type  :w . You can see the commands you type in the bottom left-hand corner of the screen.    After you have saved the file, the total number of lines and characters in the file will print out at the bottom left-hand section of the screen.   Alternatively, we can  write to file (save) and quit . Let's do that by typing  :wq . Now, you should have exited vim and returned back to your terminal window.  To edit your  draft.txt  document, open up the file again by calling vim and entering the file name:  vim draft.txt . Change to insert mode and type a few more lines (you can move around the lines using the arrows on the keyboard). This time we decide to  quit without saving  by typing  :q!", 
            "title": "Vim Saving and Quitting"
        }, 
        {
            "location": "/03_vim/#vim-editing", 
            "text": "Create the document  spider.txt  in vim. Enter the text as follows:    To make it easier to refer to distinct lines, we can add line numbers by typing  :set number .  Save the document.  Later, if you choose to remove the line numbers you can type  :set nonumber .   While we cannot point and click to navigate the document, we can use the arrow keys to move around. Navigating with arrow keys can be very slow, so Vim has shortcuts (which are completely unituitive, but very useful as you get used to them over time). Check to see what mode you are currently in. While in command mode, try moving around the screen and familarizing yourself with some of these shortcuts:         key  action      gg  to move to top of file    G  to move to bottom of file    $  to move to end of line    0  to move to beginning of line    w  to move to next word    b  to move to previous word     In addition to shortcuts for navigation, vim also offers editing shortcuts such as:     key  action      dw  to delete word    dd  to delete line    u  to undo    Ctrl + r  to redo    / pattern  to search for a pattern ( n/N  to move to next/previous match)    :%s/ search / replace /g  to search for a pattern and replace for all occurences     Practice some of the editing shortcuts, then quit the document without saving any changes.   Exercise  We have covered some basic commands in vim, but practice is key for getting comfortable with the program. Let's\npractice what we just learned in a brief challenge.   Open  spider.txt , and delete the word \"water\" from line #2.  Quit without saving.  Open  spider.txt  again, and replace every occurrence of \"spider\" with \"unicorn\".  Delete: \"Down came the rain.\"   Save the file.  Undo your previous deletion.  Redo your previous deletion.  Delete the first and last words from each of the lines.  Save the file and see whether your results match your neighbors.", 
            "title": "Vim Editing"
        }, 
        {
            "location": "/03_vim/#overview-of-vim-commands", 
            "text": "Vim modes:     key  action      i  insert mode - to write and edit text    esc  command mode - to issue commands / shortcuts     Saving and quiting:     key  action      :w  to write to file (save)    :wq  to write to file and quit    :q!  to quit without saving     Shortcuts for navigation:     key  action      gg  to move to top of file    G  to move to bottom of file    $  to move to end of line    0  to move to beginning of line    w  to move to next word    b  to move to previous word     Shortcuts for editing:     key  action      dw  to delete word    dd  to delete line    u  to undo    Ctrl + r  to redo    :set number  to number lines    :set nonumber  to remove line numbers    /pattern  to search for a pattern ( n/N  to move to next/previous match)    :%s/search/replace/g  to search for a pattern and replace for all occurences      This lesson has been developed by members of the teaching team at the  Harvard Chan Bioinformatics Core (HBC) . These are open access materials distributed under the terms of the  Creative Commons Attribution license  (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.", 
            "title": "Overview of vim commands"
        }, 
        {
            "location": "/04_loops_and_scripts/", 
            "text": "Approximate time: 60 minutes\n\n\nLearning Objectives\n\n\n\n\nCapture previous commands into a script to re-run in one single command\n\n\nUnderstanding variables and storing information\n\n\nLearn how to use variables to operate on multiple files\n\n\n\n\nNow that you've been introduced to a number of commands to interrogate your data, wouldn't it be great if you could do this for each set of data that comes in, without having to manually re-type the commands?\n\n\nWelcome to the beauty and purpose of shell scripts.\n\n\nShell scripts\n\n\nShell scripts are \ntext files that contain commands we want to run\n. As with any file, you can give a shell script any name and usually have the extension \n.sh\n. For historical reasons, a bunch of commands saved in a file is usually called a shell script, but make no mistake, this is actually a small program. \n\n\nWe are finally ready to see what makes the shell such a powerful programming environment. We are going to take the commands we repeat frequently and save them into a file so that we can \nre-run all those operations\n again later by typing \none single command\n. Let's write a shell script that will do two things:\n\n\n\n\nTell us our current working directory\n\n\nList the contents of the directory \n\n\n\n\nFirst open a new file using \nvim\n:\n\n\n$ vim listing.sh\n\n\n\n\nThen type in the following lines in the \nlisting.sh\n file:\n\n\necho \nYour current working directory is:\n\npwd\necho \nThese are the contents of this directory:\n\nls -l \n\n\n\n\nExit \nvim\n and save the file. Now let's run the new script we have created. To run a shell script you usually use the \nbash\n or \nsh\n command.\n\n\n$ sh listing.sh\n\n\n\n\n\n\nDid it work like you expected?\n\n\nWere the \necho\n commands helpful in letting you know what came next?\n\n\n\n\nThis is a very simple shell script. In this session and in upcoming sessions, we will be learning how to write more complex ones, and use the power of scripts to make our lives much easier.\n\n\nBash variables\n\n\nA \nvariable\n is a common concept shared by many programming languages. Variables are essentially a symbolic/temporary name for, or a reference to, some information. Variables are analogous to \"buckets\", where information can be stored, maintained and modified without too much hassle. \n\n\nExtending the bucket analogy: the bucket has a name associated with it, i.e. the name of the variable, and when referring to the information in the bucket, we use the name of the bucket, and do not directly refer to the actual data stored in it.\n\n\nLet's start with a simple variable that has a single number stored in it:\n\n\n$ num=25\n\n\n\n\nHow do we know that we actually created the bash variable?\n We can use the \necho\n command to print to terminal:\n\n\n$ echo num\n\n\n\n\nWhat do you see in the terminal? The \necho\n utility takes what arguments you provide and prints to terminal. In this case it interpreted \nnum\n as a a character string and simply printed it back to us. This is because \nwhen trying to retrieve the value stored in the variable, we explicitly use a \n$\n in front of it\n:\n\n\n$ echo $num\n\n\n\n\nNow you should see the number 25 returned to you. Did you notice that when we created the variable we just typed in the variable name? This is standard shell notation (syntax) for defining and using variables. When defining the variable (i.e. setting the value) you can just type it as is, but when \nretrieving the value of a variable don't forget the \n$\n!\n \n\n\nVariables can also store a string of character values. In the example below, we define a variable or a 'bucket' called \nfile\n. We will put a filename \nMov10_oe_1.subset.fq\n as the value inside the bucket.\n\n\n$ file=Mov10_oe_1.subset.fq\n\n\n\n\nOnce you press return, you should be back at the command prompt. Let's check what's stored inside \nfile\n, but first move into the \nraw_fastq\n directory::\n\n\n$ cd ~/unix_lesson/raw_fastq\n$ echo $file\n\n\n\n\nLet's try another command using the variable that we have created. We can also count the number of lines in \nMov10_oe_1.subset.fq\n by referencing the \nfile\n variable:\n\n\n$ wc -l $file\n\n\n\n\n\n\nNOTE:\n The variables we create in a session are system-wide, and independent of where you are in the filesystem. This is why we can reference it from any directory. However, it is only available for your current session. If you exit the cluster and login again at a later time, the variables you have created will no longer exist.\n\n\n\n\n\n\nExercise\n\n\n\n\nReuse the \n$file\n variable to store a different file name, and rerun the commands we ran above (\nwc -l\n, \necho\n)\n\n\n\n\n\n\nOk, so we know variables are like buckets, and so far we have seen that bucket filled with a single value. \nVariables can store more than just a single value.\n They can store multiple values and in this way can be useful to carry out many things at once. Let's create a new variable called \nfilenames\n and this time we will store \nall of the filenames\n in the \nraw_fastq\n directory as values. \n\n\nTo list all the filenames in the directory that have a \n.fq\n extension, we know the command is:\n\n\n$ ls *.fq\n\n\n\n\nNow we want to \nassign\n the output of \nls\n to the variable:\n\n\n$ filenames=`ls *.fq`\n\n\n\n\n\n\nNote the syntax for assigning output of commands to variables, i.e. the backticks around the \nls\n command.\n\n\n\n\nCheck and see what's stored inside our newly created variable using \necho\n:\n\n\n$ echo $filenames\n\n\n\n\nLet's try the \nwc -l\n command again, but this time using our new variable \nfilenames\n as the argument:\n\n\n$ wc -l $filenames\n\n\n\n\nWhat just happened? Because our variable contains multiple values, the shell runs the command on each value stored in \nfilenames\n and prints the results to screen. \n\n\n\n\nExercise\n\n\n\n\nUse some of the other commands we learned in previous lessons (i.e. \nhead\n, \ntail\n) on the \nfilenames\n variable. \n\n\n\n\n\n\nLoops\n\n\nAnother powerful concept in the Unix shell and useful when writing scripts is the concept of \"Loops\". We have just shown you that you can run a single command on multiple files by creating a variable whose values are the filenames that you wish to work on. But what if you want to \nrun a sequence of multiple commands, on multiple files\n? This is where loop come in handy!\n\n\nLooping is a concept shared by several programming languages, and its implementation in bash is very similar to other languages. \n\n\nThe structure or the syntax of (\nfor\n) loops in bash is as follows:\n\n\nfor (variable_name) in (list)\ndo\n(command1 $variable_name)\n.\n.\ndone\n\n\n\n\nwhere the \nvariable_name\n defines (or initializes) a variable that takes the value of every member of the specified \nlist\n one at a time. At each iteration, the loop retrieves the value stored in the variable (which is a member of the input list) and runs through the commands indicated between the \ndo\n and \ndone\n one at a time. \nThis syntax/structure is virtually set in stone.\n \n\n\nWhat does this loop do?\n\n\nfor x in *.fq\n do\n   echo $x\n   wc -l $x\n done\n\n\n\n\nMost simply, it writes to the terminal (\necho\n) the name of the file and the number of lines (\nwc -l\n) for each files that end in \n.fq\n in the current directory. The output is almost identical to what we had before.\n\n\nIn this case the list of files is specified using the asterisk wildcard: \n*.fq\n, i.e. all files that end in \n.fq\n. \n\n\n\n\nWhat else could we have used in place of the \nls *.fq\n?\n\n\n\n\nThen, we execute 2 commands between the \ndo\n and \ndone\n. With a loop, we execute these commands for each file at a time. Once the commands are executed for one file, the loop then executes the same commands on the next file in the list. \n\n\nEssentially, \nthe number of items in the list (variable name) == number of times the code will loop through\n, in our case that is 2 times since we have 2 files in \n~/unix_lesson/raw_fastq\n that end in \n.fq\n, and these filenames are stored in the \nfilename\n variable.\n\n\nIt doesn't matter what variable name we use, but it is advisable to make it something more intuitive. In the long run, it's best to use a name that will help point out a variable's functionality, so your future self will understand what you are thinking now.\n\n\nThe \nbasename\n command\n\n\nBefore we get started on creating more complex scripts, we want to introduce you to a command that will be useful for future scripting. The \nbasename\n command is used for extracting the base name of a file, which is accomplished using \nstring splitting to strip the directory and any suffix from filenames\n. Let's try an example, by first moving back to your home directory:\n\n\n$ cd\n\n\n\n\nThen we will run the \nbasename\n command on one of the FASTQ files. Be sure to specify the path to the file:\n\n\n$ basename ~/unix_lesson/raw_fastq/Mov10_oe_1.subset.fq\n\n\n\n\nWhat is returned to you? The filename was split into the path \nunix_lesson/raw_fastq/\n and the filename \nMov10_oe_1.subset.fq\n. The command returns only the filename. Now, suppose we wanted to also trim off the file extension (i.e. remove \n.fq\n leaving only the file \nbase name\n). We can do this by adding a parameter to the command to specify what string of characters we want trimmed.\n\n\n$ basename ~/unix_lesson/raw_fastq/Mov10_oe_1.subset.fq .fq\n\n\n\n\nYou should now see that only \nMov10_oe_1.subset\n is returned. \n\n\n\n\nExercise\n\n\n\n\nHow would you modify the above \nbasename\n command to only return \nMov10_oe_1\n?\n\n\n\n\n\n\nAutomating with Scripts\n\n\nNow that you've learned how to use loops and variables, let's put this processing power to work. Imagine, if you will, a script that will run a series of commands that would do the following for us each time we get a new data set:\n\n\n\n\nUse for loop to iterate over each FASTQ file\n\n\nGenerate a prefix to use for naming our output files\n\n\nDump out bad reads into a new file\n\n\nGet the count of the number of bad reads and generate a summary for each file\n\n\n\n\nYou might not realize it, but this is something that you now know how to do. Let's get started...\n\n\nRather than doing all of this in the terminal we are going to create a script file with all relevant commands. Move back in to \nunix_lesson\n and use \nvim\n to create our new script file:\n\n\n$ cd ~/unix_lesson\n\n$ vim generate_bad_reads_summary.sh\n\n\n\n\nWe always want to start our scripts with a shebang line: \n\n\n#!/bin/bash\n\n\n\n\nThis line is the absolute path to the Bash interpreter. The shebang line ensures that the bash shell interprets the script even if it is executed using a different shell.\n\n\nAfter the shebang line, we enter the commands we want to execute. First we want to move into our \nraw_fastq\n directory:\n\n\n# enter directory with raw FASTQs\ncd ~/unix_lesson/raw_fastq\n\n\n\n\nAnd now we loop over all the FASTQs:\n\n\n# enter directory with raw FASTQs\nfor filename in *.fq\n\n\n\n\nFor each file that we process we can use \nbasename\n to create a variable that will uniquely identify our output file based on where it originated from:\n\n\ndo\n  # create a prefix for all output files\n  base=`basename $filename .subset.fq`\n\n\n\n\nand then we execute the commands for each loop:\n\n\n  # tell us what file we're working on\n  echo $filename\n\n  # grab all the bad read records into new file\n  grep -B1 -A2 NNNNNNNNNN $filename \n $base-badreads.fastq\n\n\n\n\nWe'll also count the number of these reads and put that in a new file, using the count flag of \ngrep\n:\n\n\n  # grab the number of bad reads and write it to a summary file\n  grep -cH NNNNNNNNNN $filename \n $base-badreads.count.summary\ndone\n\n\n\n\nIf you've noticed, we used a new \ngrep\n flag \n-H\n above; this flag will report the filename along with the match string. This is useful for when we generate the summary file.\n\n\nSave and exit \nvim\n, and voila! You now have a script you can use to assess the quality of all your new datasets. Your finished script, complete with comments, should look like the following:\n\n\n#!/bin/bash \n\n# enter directory with raw FASTQs\ncd ~/unix_lesson/raw_fastq\n\n# count bad reads for each FASTQ file in our directory\nfor filename in *.fq \ndo \n\n  # create a prefix for all output files\n  base=`basename $filename .subset.fq`\n\n  # tell us what file we're working on  \n  echo $filename\n\n  # grab all the bad read records\n  grep -B1 -A2 NNNNNNNNNN $filename \n $base-badreads.fastq\n\n  # grab the number of bad reads and write it to a summary file\n  grep -cH NNNNNNNNNN $filename \n $base-badreads.count.summary\ndone\n\n\n\n\n\nTo run this script, we simply enter the following command:\n\n\n$ sh generate_bad_reads_summary.sh\n\n\n\n\nHow do we know if the script worked? Take a look inside the \nraw_fastq\n directory, we should see that for every one of the original FASTQ files we have two associated bad read files.\n\n\n$ ls -l ~/unix_lesson/raw_fastq \n\n\n\n\nTo keep our data organized, let's move all of the bad read files out of the \nraw_fastq\n directory into a new directory called \nother\n, and the script to a new directory called \nscripts\n.\n\n\n$ mv raw_fastq/*bad* other/\n\n$ mkdir scripts\n$ mv *.sh scripts/\n\n\n\n\n\n\nThis lesson has been developed by members of the teaching team at the \nHarvard Chan Bioinformatics Core (HBC)\n. These are open access materials distributed under the terms of the \nCreative Commons Attribution license\n (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\n\n\n\nThe materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the \nCreative Commons Attribution license\n (CC BY 4.0).\n\n\nAdapted from the lesson by Tracy Teal. Original contributors: Paul Wilson, Milad Fatenejad, Sasha Wood and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Shell scripts and `for` loops"
        }, 
        {
            "location": "/04_loops_and_scripts/#learning-objectives", 
            "text": "Capture previous commands into a script to re-run in one single command  Understanding variables and storing information  Learn how to use variables to operate on multiple files   Now that you've been introduced to a number of commands to interrogate your data, wouldn't it be great if you could do this for each set of data that comes in, without having to manually re-type the commands?  Welcome to the beauty and purpose of shell scripts.", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/04_loops_and_scripts/#shell-scripts", 
            "text": "Shell scripts are  text files that contain commands we want to run . As with any file, you can give a shell script any name and usually have the extension  .sh . For historical reasons, a bunch of commands saved in a file is usually called a shell script, but make no mistake, this is actually a small program.   We are finally ready to see what makes the shell such a powerful programming environment. We are going to take the commands we repeat frequently and save them into a file so that we can  re-run all those operations  again later by typing  one single command . Let's write a shell script that will do two things:   Tell us our current working directory  List the contents of the directory    First open a new file using  vim :  $ vim listing.sh  Then type in the following lines in the  listing.sh  file:  echo  Your current working directory is: \npwd\necho  These are the contents of this directory: \nls -l   Exit  vim  and save the file. Now let's run the new script we have created. To run a shell script you usually use the  bash  or  sh  command.  $ sh listing.sh   Did it work like you expected?  Were the  echo  commands helpful in letting you know what came next?   This is a very simple shell script. In this session and in upcoming sessions, we will be learning how to write more complex ones, and use the power of scripts to make our lives much easier.", 
            "title": "Shell scripts"
        }, 
        {
            "location": "/04_loops_and_scripts/#bash-variables", 
            "text": "A  variable  is a common concept shared by many programming languages. Variables are essentially a symbolic/temporary name for, or a reference to, some information. Variables are analogous to \"buckets\", where information can be stored, maintained and modified without too much hassle.   Extending the bucket analogy: the bucket has a name associated with it, i.e. the name of the variable, and when referring to the information in the bucket, we use the name of the bucket, and do not directly refer to the actual data stored in it.  Let's start with a simple variable that has a single number stored in it:  $ num=25  How do we know that we actually created the bash variable?  We can use the  echo  command to print to terminal:  $ echo num  What do you see in the terminal? The  echo  utility takes what arguments you provide and prints to terminal. In this case it interpreted  num  as a a character string and simply printed it back to us. This is because  when trying to retrieve the value stored in the variable, we explicitly use a  $  in front of it :  $ echo $num  Now you should see the number 25 returned to you. Did you notice that when we created the variable we just typed in the variable name? This is standard shell notation (syntax) for defining and using variables. When defining the variable (i.e. setting the value) you can just type it as is, but when  retrieving the value of a variable don't forget the  $ !    Variables can also store a string of character values. In the example below, we define a variable or a 'bucket' called  file . We will put a filename  Mov10_oe_1.subset.fq  as the value inside the bucket.  $ file=Mov10_oe_1.subset.fq  Once you press return, you should be back at the command prompt. Let's check what's stored inside  file , but first move into the  raw_fastq  directory::  $ cd ~/unix_lesson/raw_fastq\n$ echo $file  Let's try another command using the variable that we have created. We can also count the number of lines in  Mov10_oe_1.subset.fq  by referencing the  file  variable:  $ wc -l $file   NOTE:  The variables we create in a session are system-wide, and independent of where you are in the filesystem. This is why we can reference it from any directory. However, it is only available for your current session. If you exit the cluster and login again at a later time, the variables you have created will no longer exist.    Exercise   Reuse the  $file  variable to store a different file name, and rerun the commands we ran above ( wc -l ,  echo )    Ok, so we know variables are like buckets, and so far we have seen that bucket filled with a single value.  Variables can store more than just a single value.  They can store multiple values and in this way can be useful to carry out many things at once. Let's create a new variable called  filenames  and this time we will store  all of the filenames  in the  raw_fastq  directory as values.   To list all the filenames in the directory that have a  .fq  extension, we know the command is:  $ ls *.fq  Now we want to  assign  the output of  ls  to the variable:  $ filenames=`ls *.fq`   Note the syntax for assigning output of commands to variables, i.e. the backticks around the  ls  command.   Check and see what's stored inside our newly created variable using  echo :  $ echo $filenames  Let's try the  wc -l  command again, but this time using our new variable  filenames  as the argument:  $ wc -l $filenames  What just happened? Because our variable contains multiple values, the shell runs the command on each value stored in  filenames  and prints the results to screen.    Exercise   Use some of the other commands we learned in previous lessons (i.e.  head ,  tail ) on the  filenames  variable.", 
            "title": "Bash variables"
        }, 
        {
            "location": "/04_loops_and_scripts/#loops", 
            "text": "Another powerful concept in the Unix shell and useful when writing scripts is the concept of \"Loops\". We have just shown you that you can run a single command on multiple files by creating a variable whose values are the filenames that you wish to work on. But what if you want to  run a sequence of multiple commands, on multiple files ? This is where loop come in handy!  Looping is a concept shared by several programming languages, and its implementation in bash is very similar to other languages.   The structure or the syntax of ( for ) loops in bash is as follows:  for (variable_name) in (list)\ndo\n(command1 $variable_name)\n.\n.\ndone  where the  variable_name  defines (or initializes) a variable that takes the value of every member of the specified  list  one at a time. At each iteration, the loop retrieves the value stored in the variable (which is a member of the input list) and runs through the commands indicated between the  do  and  done  one at a time.  This syntax/structure is virtually set in stone.", 
            "title": "Loops"
        }, 
        {
            "location": "/04_loops_and_scripts/#what-does-this-loop-do", 
            "text": "for x in *.fq\n do\n   echo $x\n   wc -l $x\n done  Most simply, it writes to the terminal ( echo ) the name of the file and the number of lines ( wc -l ) for each files that end in  .fq  in the current directory. The output is almost identical to what we had before.  In this case the list of files is specified using the asterisk wildcard:  *.fq , i.e. all files that end in  .fq .    What else could we have used in place of the  ls *.fq ?   Then, we execute 2 commands between the  do  and  done . With a loop, we execute these commands for each file at a time. Once the commands are executed for one file, the loop then executes the same commands on the next file in the list.   Essentially,  the number of items in the list (variable name) == number of times the code will loop through , in our case that is 2 times since we have 2 files in  ~/unix_lesson/raw_fastq  that end in  .fq , and these filenames are stored in the  filename  variable.  It doesn't matter what variable name we use, but it is advisable to make it something more intuitive. In the long run, it's best to use a name that will help point out a variable's functionality, so your future self will understand what you are thinking now.", 
            "title": "What does this loop do?"
        }, 
        {
            "location": "/04_loops_and_scripts/#the-basename-command", 
            "text": "Before we get started on creating more complex scripts, we want to introduce you to a command that will be useful for future scripting. The  basename  command is used for extracting the base name of a file, which is accomplished using  string splitting to strip the directory and any suffix from filenames . Let's try an example, by first moving back to your home directory:  $ cd  Then we will run the  basename  command on one of the FASTQ files. Be sure to specify the path to the file:  $ basename ~/unix_lesson/raw_fastq/Mov10_oe_1.subset.fq  What is returned to you? The filename was split into the path  unix_lesson/raw_fastq/  and the filename  Mov10_oe_1.subset.fq . The command returns only the filename. Now, suppose we wanted to also trim off the file extension (i.e. remove  .fq  leaving only the file  base name ). We can do this by adding a parameter to the command to specify what string of characters we want trimmed.  $ basename ~/unix_lesson/raw_fastq/Mov10_oe_1.subset.fq .fq  You should now see that only  Mov10_oe_1.subset  is returned.    Exercise   How would you modify the above  basename  command to only return  Mov10_oe_1 ?", 
            "title": "The basename command"
        }, 
        {
            "location": "/04_loops_and_scripts/#automating-with-scripts", 
            "text": "Now that you've learned how to use loops and variables, let's put this processing power to work. Imagine, if you will, a script that will run a series of commands that would do the following for us each time we get a new data set:   Use for loop to iterate over each FASTQ file  Generate a prefix to use for naming our output files  Dump out bad reads into a new file  Get the count of the number of bad reads and generate a summary for each file   You might not realize it, but this is something that you now know how to do. Let's get started...  Rather than doing all of this in the terminal we are going to create a script file with all relevant commands. Move back in to  unix_lesson  and use  vim  to create our new script file:  $ cd ~/unix_lesson\n\n$ vim generate_bad_reads_summary.sh  We always want to start our scripts with a shebang line:   #!/bin/bash  This line is the absolute path to the Bash interpreter. The shebang line ensures that the bash shell interprets the script even if it is executed using a different shell.  After the shebang line, we enter the commands we want to execute. First we want to move into our  raw_fastq  directory:  # enter directory with raw FASTQs\ncd ~/unix_lesson/raw_fastq  And now we loop over all the FASTQs:  # enter directory with raw FASTQs\nfor filename in *.fq  For each file that we process we can use  basename  to create a variable that will uniquely identify our output file based on where it originated from:  do\n  # create a prefix for all output files\n  base=`basename $filename .subset.fq`  and then we execute the commands for each loop:    # tell us what file we're working on\n  echo $filename\n\n  # grab all the bad read records into new file\n  grep -B1 -A2 NNNNNNNNNN $filename   $base-badreads.fastq  We'll also count the number of these reads and put that in a new file, using the count flag of  grep :    # grab the number of bad reads and write it to a summary file\n  grep -cH NNNNNNNNNN $filename   $base-badreads.count.summary\ndone  If you've noticed, we used a new  grep  flag  -H  above; this flag will report the filename along with the match string. This is useful for when we generate the summary file.  Save and exit  vim , and voila! You now have a script you can use to assess the quality of all your new datasets. Your finished script, complete with comments, should look like the following:  #!/bin/bash \n\n# enter directory with raw FASTQs\ncd ~/unix_lesson/raw_fastq\n\n# count bad reads for each FASTQ file in our directory\nfor filename in *.fq \ndo \n\n  # create a prefix for all output files\n  base=`basename $filename .subset.fq`\n\n  # tell us what file we're working on  \n  echo $filename\n\n  # grab all the bad read records\n  grep -B1 -A2 NNNNNNNNNN $filename   $base-badreads.fastq\n\n  # grab the number of bad reads and write it to a summary file\n  grep -cH NNNNNNNNNN $filename   $base-badreads.count.summary\ndone  To run this script, we simply enter the following command:  $ sh generate_bad_reads_summary.sh  How do we know if the script worked? Take a look inside the  raw_fastq  directory, we should see that for every one of the original FASTQ files we have two associated bad read files.  $ ls -l ~/unix_lesson/raw_fastq   To keep our data organized, let's move all of the bad read files out of the  raw_fastq  directory into a new directory called  other , and the script to a new directory called  scripts .  $ mv raw_fastq/*bad* other/\n\n$ mkdir scripts\n$ mv *.sh scripts/   This lesson has been developed by members of the teaching team at the  Harvard Chan Bioinformatics Core (HBC) . These are open access materials distributed under the terms of the  Creative Commons Attribution license  (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.   The materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the  Creative Commons Attribution license  (CC BY 4.0).  Adapted from the lesson by Tracy Teal. Original contributors: Paul Wilson, Milad Fatenejad, Sasha Wood and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Automating with Scripts"
        }, 
        {
            "location": "/05_permissions_and_environment_variables/", 
            "text": "Approximate time: 40 minutes\n\n\nLearning Objectives\n\n\n\n\nHow to grant or restrict access to files on a multi-user UNIX system\n\n\nWhat is an \"Environment Variable\" in a shell.\n\n\nWhat is $PATH, and why I should care.\n\n\n\n\nPermissions\n\n\nUnix controls who can read, modify, and run files using \npermissions\n.\n\n\nUsers of a multi-user UNIX system can belong to any number of groups.\n\n\nLet's see what groups we all belong to:\n\n\n$ groups\n\n\n\n\nDepending on our affiliation, we all belong to at least a couple of groups. I belong to 4 groups,\n\n rsk27\n\n bcbio\n\n hbctraining\n\n Domain_Users\n\n\nAs you can imagine, on a shared system it is important to protect each user's data. To start, every file and directory on a Unix computer belongs to one owner and one group. Along with each file's content, the operating system stores the information about the user and group that own it, which is the \"metadata\" for a given file.\n\n\nThe user-and-group model means that for each file every user on the system falls into one of three categories:\n\n\n\n\nthe owner of the file\n\n\na member of the group the file belongs to\n\n\nand everyone else.\n\n\n\n\nFor each of these three categories, the computer keeps track of whether people in that category can read the file, write to the file, or execute the file (i.e., run it if it is a program).\n\n\nLet's look at this model in action by running the command \nls -l /n/groups/hbctraining/\n, to list the files in that directory:\n\n\n$ ls -l /n/groups/hbctraining/\n\ndrwxrwsr-x  4 mm573 hbctraining 831 Feb 29  2016 bcbio-rnaseq\ndrwxrwsr-x 12 mm573 hbctraining 318 May 24 11:13 chip-seq\n-rw-r--r--  1 root  hbctraining   0 Apr  5  2015 copy_me.txt\ndrwxrwsr-x  3 rsk27 hbctraining 201 Apr  5  2015 exercises\ndrwxrwsr-x  6 rsk27 hbctraining 293 Oct 27 09:40 for_chipseq\ndrwxrwsr-x  4 mp298 hbctraining  51 Dec  6  2016 mep-data\ndrwxrwsr-x  4 rsk27 hbctraining  53 Jun  2 15:57 ngs_course\ndrwxrwsr-x  4 rsk27 hbctraining  53 Nov  2  2016 ngs-course_backup_Nov1-2016\ndrwxrwsr-x  6 mm573 hbctraining 107 Mar 24  2016 ngs-data-analysis2016\n.\n.\n.\n.\n\n\n\n\nThe \n-l\n flag tells \nls\n to give us a long-form listing. It's a lot of information, so let's go through the columns in turn.\n\n\nOn the right side, we have the files' names. Next to them, moving left, are the times and dates they were last modified. Backup systems and other tools use this information in a variety of ways, but you can use it to tell when you (or anyone else with permission) last changed a file.\n\n\nNext to the modification time is the file's size in bytes and the names of the user and group that owns it. In this case, it is the eCommons IDs denoting either Mary, Meeta or me as an owner and \nhbctraining\n is the associated group. \n\n\nNow, take a look at the \nunix_lesson\n directory in your home directory to explore that first column a little more:\n\n\nls -l ~/unix_lesson/\n\ndrwxrwsr-x 2 rsk27 rsk27  78 Aug 22 21:08 genomics_data\ndrwxrwsr-x 2 rsk27 rsk27 725 Aug 22 21:16 other\ndrwxrwsr-x 2 rsk27 rsk27 256 Aug 22 21:16 raw_fastq\n-rw-rw-r-- 1 rsk27 rsk27 377 Sep 22 10:00 README.txt\ndrwxrwsr-x 2 rsk27 rsk27  62 Aug 22 21:07 reference_data\n\n\n\n\nWho is the owner of the files in this directory? Which group do the files belong to?\n\n\nBasically, O2 has you (your account ID) listed both as an owner and a group, and this is usually the assignment for the files and folders in your personal directory.\n\n\nWe'll skip over the second column for now (the one showing \n1\n for each file), because it's the first column that we care about most. This shows the file's permissions, i.e., who can read, write, or execute it.\n\n\nLet's have a closer look at one of those permission strings for README.txt:\n\n\n-rw-rw-r--\n\n\n\n\nThe first character\n tells us whether the listing is a regular file \n-\n or a directory \nd\n, or there may be some other character meaning more esoteric things. In this case, it is \n-\n which means it is a regular file.\n\n\nThe next 9 characters are usually some combination of the following in the order listed below:\n\n\nr\n = read permission\n\n\nw\n = write/modify permission\n\n\nx\n = execute permission (run a script/program or traverse a directory).\n\n\n\n\nSometimes the \nx\n is replaced by another character, but it is beyond the scope of today's class. You can \nget more information here\n, if you are interested.\n\n\nTo see an example of a file that is actually executable, try \nls -l /bin/ls\n.\n\n\n\n\nThe \nnext three characters\n tell us what permissions the file's \nowner\n has. Here, the owner can read and write the file: \nrw-\n. \n\n\nThe \nmiddle triplet\n shows us the \ngroup's permissions\n. If the permission is turned off, we see a dash, so \nrw-\n means \"read and write, but not execute\". (In this case the group and the owner are the same so it makes sense that this is the same for both.)\n\n\nThe \nfinal triplet\n shows us what everyone who isn't the file's owner, or in the file's group, can do. In this case, it's \nr--\n again, so \neveryone else\n on the system can read the file's contents.\n\n\nNow, if we take a look at the permissions for directories (e.g. \ndrwxrwsr-x\n): the \nx\n for the permissions here indicates that \"execute\" is turned on. What does that mean, given that a directory isn't a program or an executable file, we can't \"execute\" it? \n\n\nWell, \nx\n means something different for directories. It gives someone the right to \ntraverse\n the directory, but not to look at its contents. This is beyond the scope of today's class, but note that you can give access to a specific file that's deep inside a directory structure without giving them access to all the files and sub-directories within.\n\n\nChanging permissions\n\n\nTo change permissions, we use the \nchmod\n command (whose name stands for \"change mode\"). Let's make our README.txt file \ninaccessible\n to all users other than you and the group the file belong to (you, in this case), currently they are able to read it:\n\n\n$ ls -l ~/unix_lesson/README.txt\n\n-rw-rw-r-- 1 rsk27 rsk27 377 Oct  6 10:28 /home/rsk27/unix_lesson/README.txt\n\n$ chmod o-rw ~/unix_lesson/README.txt         # the \n-\n after o denotes removing that permission\n\n$ ls -l ~/unix_lesson/README.txt\n\n-rw-rw---- 1 rsk27 rsk27 377 Oct  6 10:28 /home/rsk27/unix_lesson/README.txt\n\n\n\n\nThe \no\n signals that we're changing the privileges of \"others\".\n\n\nLet's change it back to allow it to be readable by others:\n\n\n$ chmod o+r ~/unix_lesson/README.txt         # the \n+\n after o denotes adding/giving that permission\n\n$ ls -l ~/unix_lesson/README.txt\n\n-rw-rw-r-- 1 rsk27 rsk27 377 Oct  6 10:28 /home/rsk27/unix_lesson/README.txt\n\n\n\n\nIf we wanted to make this an executable file for ourselves (the file's owners) we would say \nchmod u+rwx\n, where the \nu\n signals that we are changing permission for the file's owner. To change permissions for the \"group\", you'd use the letter \ng\n, e.g. \nchmod g-w\n. \n\n\n\n\n\n\nThe fact that something is marked as executable doesn't actually mean it contains or is a program of some kind. We could easily mark the \n~/unix_lesson/raw_fastq/Irrel_kd_1.subset.fq\n file as executable using \nchmod\n. Depending on the operating system we're using, trying to \"run\" it will fail (because it doesn't contain instructions the computer recognizes, i.e. it is not a script of some type).\n\n\n\n\n\n\n\n\nExercise\n\n\nIf \nls -l myfile.php\n returns the following details:\n\n\n-rwxr-xr-- 1 caro zoo  2312  2014-10-25 18:30 myfile.php\n\n\n\n\nWhich of the following statements is true?\n\n\n\n\nmembers of caro (a group) can read, write, and execute myfile.php\n\n\nmembers of zoo (a group) cannot execute myfile.php\n\n\ncaro (the owner) can read, write, and execute myfile.php\n\n\n\n\n\n\nEnvironment Variables\n\n\nEnvironment variables are, in short, variables that describe the environment in which programs run, and they are predefined for a given computer or cluster that you are on. You can reset them to customize the environment. Two commonly encountered environment variables are \n$HOME\n and \n$PATH\n.\n\n\n\n\n$HOME\n defines the full path for the home directory of a given user.\n\n\n$PATH\n defines a list of directories to search in when looking for a command/program to execute.\n\n\n\n\nIn the context of the shell the environment variables are usually all in upper case.\n\n\nFirst, let's see our list of environmental variables:\n\n\n$ env\n\n\n\n\nLet's see what is stored in these variables:\n\n\n$ echo $HOME\n\n\n\n\nVariables, in most systems, are called or denoted with a \"$\" before the variable name, just like a regular variable.\n\n\n$ echo $PATH\n\n/opt/lsf/7.0/linux2.6-glibc2.3-x86_64/bin:/groups/bcbio/bcbio/anaconda/bin:/opt/bcbio/local/bin:/opt/lsf/7.0/linux2.6-glibc2.3-x86_64/etc:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin\n\n\n\n\nI have a lot of full/absolute paths in my $PATH variable, which are separated from each other by a \":\"; here is the list in a more readable format:\n\n\n\n\n/n/cluster/bin\n\n\n/n/app/bcbio/tools/bin\n\n\n/usr/local/bin\n\n\n/usr/bin\n\n\n/usr/local/sbin\n\n\n/usr/sbin\n\n\n/opt/puppetlabs/bin\n\n\n\n\nThese are the directories that the shell will look through (in the same order as they are listed) for a command or an executable file that you type on the command prompt.\n\n\nWhen someone says that a command or an executable file is \"in my path\", they mean that the parent directory for that command/file is contained in the list within the $PATH variable. \n\n\nFor any command you execute on the command prompt, you can find out where they are located using the \nwhich\n command.\n\n\nTry it on a few of the basic commands we have learned so far:\n\n\n$ which ls\n$ which \nyour favorite command\n\n$ which \nyour favorite command\n\n\n\n\n\nAre the directories listed by the \nwhich\n command within \n$PATH\n?\n\n\n\n\nModifying Environment Variables\n\n\nIf you are interested in adding a new entry to the path variable, the command to use is \nexport\n. This command is usually executed as follows: \n\n\nexport PATH=$PATH:~/opt/bin\n, which tells the shell to add the \n~/opt/bin\n directory to the end of the preexisting list within \n$PATH\n. Alternatively, if you use \nexport PATH=~/opt/bin:$PATH\n, the same directory will be added to the beginning of the list. The order determines which directory the shell will look in first to find a program.\n\n\n\n\nCloser look at the inner workings of the shell, in the context of $PATH\n\n\nThe $PATH variable is reset to a set of defaults (/bin:/usr/bin and so on), each time you start a new shell Terminal. To make sure that a command/program you need is always at your fingertips, you have to put it in one of 2 special shell scripts that are always run when you start a new terminal. These are hidden files in your home directory called \n.bashrc\n and \n.bash_profile\n. You can create them if they don't exist, and shell will use them.\n\n\nCheck what hidden files exist in our home directory using the \n-a\n flag:\n\n\n$ ls -al ~/\n\n\n\n\nSuppose we want to add \n/n/app/bcbio/tools/bin\n to the beginning of the list in \n$PATH\n. This directory contains executables for many tools useful for NGS analysis. We can add this location by including an \nexport\n command to do this at the end of the \n.bashrc\n file, this will make it so that when you start a new shell session the location will always be in your path. \n\n\nOpen the \n.bashrc\n file using \nvim\n and at the end of the file add the export command that adds a specific location to the list in \n$PATH\n. \n\n\n$ vim ~/.bashrc\n\n# at the end of the file type in the following - export PATH=/n/app/bcbio/tools/bin:$PATH\n# Don't forget the \n:\n between the full path and the \n$PATH\n!\n\n\n\n\nIn closing, permissions and environment variables, especially \n$PATH\n, are very useful and important concepts to understand in the context of UNIX and HPC.\n\n\n\n\nThis lesson has been developed by members of the teaching team at the \nHarvard Chan Bioinformatics Core (HBC)\n. These are open access materials distributed under the terms of the \nCreative Commons Attribution license\n (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\n\n\n\n\nThe materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the \nCreative Commons Attribution license\n (CC BY 4.0).\n\n\nAdapted from the lesson by Tracy Teal. Original contributors: Paul Wilson, Milad Fatenejad, Sasha Wood and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Permissions and environment variable"
        }, 
        {
            "location": "/05_permissions_and_environment_variables/#learning-objectives", 
            "text": "How to grant or restrict access to files on a multi-user UNIX system  What is an \"Environment Variable\" in a shell.  What is $PATH, and why I should care.", 
            "title": "Learning Objectives"
        }, 
        {
            "location": "/05_permissions_and_environment_variables/#permissions", 
            "text": "Unix controls who can read, modify, and run files using  permissions .  Users of a multi-user UNIX system can belong to any number of groups.  Let's see what groups we all belong to:  $ groups  Depending on our affiliation, we all belong to at least a couple of groups. I belong to 4 groups,  rsk27  bcbio  hbctraining  Domain_Users  As you can imagine, on a shared system it is important to protect each user's data. To start, every file and directory on a Unix computer belongs to one owner and one group. Along with each file's content, the operating system stores the information about the user and group that own it, which is the \"metadata\" for a given file.  The user-and-group model means that for each file every user on the system falls into one of three categories:   the owner of the file  a member of the group the file belongs to  and everyone else.   For each of these three categories, the computer keeps track of whether people in that category can read the file, write to the file, or execute the file (i.e., run it if it is a program).  Let's look at this model in action by running the command  ls -l /n/groups/hbctraining/ , to list the files in that directory:  $ ls -l /n/groups/hbctraining/\n\ndrwxrwsr-x  4 mm573 hbctraining 831 Feb 29  2016 bcbio-rnaseq\ndrwxrwsr-x 12 mm573 hbctraining 318 May 24 11:13 chip-seq\n-rw-r--r--  1 root  hbctraining   0 Apr  5  2015 copy_me.txt\ndrwxrwsr-x  3 rsk27 hbctraining 201 Apr  5  2015 exercises\ndrwxrwsr-x  6 rsk27 hbctraining 293 Oct 27 09:40 for_chipseq\ndrwxrwsr-x  4 mp298 hbctraining  51 Dec  6  2016 mep-data\ndrwxrwsr-x  4 rsk27 hbctraining  53 Jun  2 15:57 ngs_course\ndrwxrwsr-x  4 rsk27 hbctraining  53 Nov  2  2016 ngs-course_backup_Nov1-2016\ndrwxrwsr-x  6 mm573 hbctraining 107 Mar 24  2016 ngs-data-analysis2016\n.\n.\n.\n.  The  -l  flag tells  ls  to give us a long-form listing. It's a lot of information, so let's go through the columns in turn.  On the right side, we have the files' names. Next to them, moving left, are the times and dates they were last modified. Backup systems and other tools use this information in a variety of ways, but you can use it to tell when you (or anyone else with permission) last changed a file.  Next to the modification time is the file's size in bytes and the names of the user and group that owns it. In this case, it is the eCommons IDs denoting either Mary, Meeta or me as an owner and  hbctraining  is the associated group.   Now, take a look at the  unix_lesson  directory in your home directory to explore that first column a little more:  ls -l ~/unix_lesson/\n\ndrwxrwsr-x 2 rsk27 rsk27  78 Aug 22 21:08 genomics_data\ndrwxrwsr-x 2 rsk27 rsk27 725 Aug 22 21:16 other\ndrwxrwsr-x 2 rsk27 rsk27 256 Aug 22 21:16 raw_fastq\n-rw-rw-r-- 1 rsk27 rsk27 377 Sep 22 10:00 README.txt\ndrwxrwsr-x 2 rsk27 rsk27  62 Aug 22 21:07 reference_data  Who is the owner of the files in this directory? Which group do the files belong to?  Basically, O2 has you (your account ID) listed both as an owner and a group, and this is usually the assignment for the files and folders in your personal directory.  We'll skip over the second column for now (the one showing  1  for each file), because it's the first column that we care about most. This shows the file's permissions, i.e., who can read, write, or execute it.  Let's have a closer look at one of those permission strings for README.txt:  -rw-rw-r--  The first character  tells us whether the listing is a regular file  -  or a directory  d , or there may be some other character meaning more esoteric things. In this case, it is  -  which means it is a regular file.  The next 9 characters are usually some combination of the following in the order listed below:  r  = read permission  w  = write/modify permission  x  = execute permission (run a script/program or traverse a directory).   Sometimes the  x  is replaced by another character, but it is beyond the scope of today's class. You can  get more information here , if you are interested.  To see an example of a file that is actually executable, try  ls -l /bin/ls .   The  next three characters  tell us what permissions the file's  owner  has. Here, the owner can read and write the file:  rw- .   The  middle triplet  shows us the  group's permissions . If the permission is turned off, we see a dash, so  rw-  means \"read and write, but not execute\". (In this case the group and the owner are the same so it makes sense that this is the same for both.)  The  final triplet  shows us what everyone who isn't the file's owner, or in the file's group, can do. In this case, it's  r--  again, so  everyone else  on the system can read the file's contents.  Now, if we take a look at the permissions for directories (e.g.  drwxrwsr-x ): the  x  for the permissions here indicates that \"execute\" is turned on. What does that mean, given that a directory isn't a program or an executable file, we can't \"execute\" it?   Well,  x  means something different for directories. It gives someone the right to  traverse  the directory, but not to look at its contents. This is beyond the scope of today's class, but note that you can give access to a specific file that's deep inside a directory structure without giving them access to all the files and sub-directories within.", 
            "title": "Permissions"
        }, 
        {
            "location": "/05_permissions_and_environment_variables/#changing-permissions", 
            "text": "To change permissions, we use the  chmod  command (whose name stands for \"change mode\"). Let's make our README.txt file  inaccessible  to all users other than you and the group the file belong to (you, in this case), currently they are able to read it:  $ ls -l ~/unix_lesson/README.txt\n\n-rw-rw-r-- 1 rsk27 rsk27 377 Oct  6 10:28 /home/rsk27/unix_lesson/README.txt\n\n$ chmod o-rw ~/unix_lesson/README.txt         # the  -  after o denotes removing that permission\n\n$ ls -l ~/unix_lesson/README.txt\n\n-rw-rw---- 1 rsk27 rsk27 377 Oct  6 10:28 /home/rsk27/unix_lesson/README.txt  The  o  signals that we're changing the privileges of \"others\".  Let's change it back to allow it to be readable by others:  $ chmod o+r ~/unix_lesson/README.txt         # the  +  after o denotes adding/giving that permission\n\n$ ls -l ~/unix_lesson/README.txt\n\n-rw-rw-r-- 1 rsk27 rsk27 377 Oct  6 10:28 /home/rsk27/unix_lesson/README.txt  If we wanted to make this an executable file for ourselves (the file's owners) we would say  chmod u+rwx , where the  u  signals that we are changing permission for the file's owner. To change permissions for the \"group\", you'd use the letter  g , e.g.  chmod g-w .     The fact that something is marked as executable doesn't actually mean it contains or is a program of some kind. We could easily mark the  ~/unix_lesson/raw_fastq/Irrel_kd_1.subset.fq  file as executable using  chmod . Depending on the operating system we're using, trying to \"run\" it will fail (because it doesn't contain instructions the computer recognizes, i.e. it is not a script of some type).     Exercise  If  ls -l myfile.php  returns the following details:  -rwxr-xr-- 1 caro zoo  2312  2014-10-25 18:30 myfile.php  Which of the following statements is true?   members of caro (a group) can read, write, and execute myfile.php  members of zoo (a group) cannot execute myfile.php  caro (the owner) can read, write, and execute myfile.php", 
            "title": "Changing permissions"
        }, 
        {
            "location": "/05_permissions_and_environment_variables/#environment-variables", 
            "text": "Environment variables are, in short, variables that describe the environment in which programs run, and they are predefined for a given computer or cluster that you are on. You can reset them to customize the environment. Two commonly encountered environment variables are  $HOME  and  $PATH .   $HOME  defines the full path for the home directory of a given user.  $PATH  defines a list of directories to search in when looking for a command/program to execute.   In the context of the shell the environment variables are usually all in upper case.  First, let's see our list of environmental variables:  $ env  Let's see what is stored in these variables:  $ echo $HOME  Variables, in most systems, are called or denoted with a \"$\" before the variable name, just like a regular variable.  $ echo $PATH\n\n/opt/lsf/7.0/linux2.6-glibc2.3-x86_64/bin:/groups/bcbio/bcbio/anaconda/bin:/opt/bcbio/local/bin:/opt/lsf/7.0/linux2.6-glibc2.3-x86_64/etc:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin  I have a lot of full/absolute paths in my $PATH variable, which are separated from each other by a \":\"; here is the list in a more readable format:   /n/cluster/bin  /n/app/bcbio/tools/bin  /usr/local/bin  /usr/bin  /usr/local/sbin  /usr/sbin  /opt/puppetlabs/bin   These are the directories that the shell will look through (in the same order as they are listed) for a command or an executable file that you type on the command prompt.  When someone says that a command or an executable file is \"in my path\", they mean that the parent directory for that command/file is contained in the list within the $PATH variable.   For any command you execute on the command prompt, you can find out where they are located using the  which  command.  Try it on a few of the basic commands we have learned so far:  $ which ls\n$ which  your favorite command \n$ which  your favorite command   Are the directories listed by the  which  command within  $PATH ?", 
            "title": "Environment Variables"
        }, 
        {
            "location": "/05_permissions_and_environment_variables/#modifying-environment-variables", 
            "text": "If you are interested in adding a new entry to the path variable, the command to use is  export . This command is usually executed as follows:   export PATH=$PATH:~/opt/bin , which tells the shell to add the  ~/opt/bin  directory to the end of the preexisting list within  $PATH . Alternatively, if you use  export PATH=~/opt/bin:$PATH , the same directory will be added to the beginning of the list. The order determines which directory the shell will look in first to find a program.", 
            "title": "Modifying Environment Variables"
        }, 
        {
            "location": "/05_permissions_and_environment_variables/#closer-look-at-the-inner-workings-of-the-shell-in-the-context-of-path", 
            "text": "The $PATH variable is reset to a set of defaults (/bin:/usr/bin and so on), each time you start a new shell Terminal. To make sure that a command/program you need is always at your fingertips, you have to put it in one of 2 special shell scripts that are always run when you start a new terminal. These are hidden files in your home directory called  .bashrc  and  .bash_profile . You can create them if they don't exist, and shell will use them.  Check what hidden files exist in our home directory using the  -a  flag:  $ ls -al ~/  Suppose we want to add  /n/app/bcbio/tools/bin  to the beginning of the list in  $PATH . This directory contains executables for many tools useful for NGS analysis. We can add this location by including an  export  command to do this at the end of the  .bashrc  file, this will make it so that when you start a new shell session the location will always be in your path.   Open the  .bashrc  file using  vim  and at the end of the file add the export command that adds a specific location to the list in  $PATH .   $ vim ~/.bashrc\n\n# at the end of the file type in the following - export PATH=/n/app/bcbio/tools/bin:$PATH\n# Don't forget the  :  between the full path and the  $PATH !  In closing, permissions and environment variables, especially  $PATH , are very useful and important concepts to understand in the context of UNIX and HPC.   This lesson has been developed by members of the teaching team at the  Harvard Chan Bioinformatics Core (HBC) . These are open access materials distributed under the terms of the  Creative Commons Attribution license  (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.   The materials used in this lesson were derived from work that is Copyright \u00a9 Data Carpentry (http://datacarpentry.org/). \nAll Data Carpentry instructional material is made available under the  Creative Commons Attribution license  (CC BY 4.0).  Adapted from the lesson by Tracy Teal. Original contributors: Paul Wilson, Milad Fatenejad, Sasha Wood and Radhika Khetani for Software Carpentry (http://software-carpentry.org/)", 
            "title": "Closer look at the inner workings of the shell, in the context of $PATH"
        }
    ]
}